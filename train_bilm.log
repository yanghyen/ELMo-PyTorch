2025-12-08 13:36:58,926 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:36:58,987 - INFO - Using device: cuda
2025-12-08 13:36:59,004 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:36:59,004 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:37:00,983 - INFO - Loaded vocabulary: 6 words
2025-12-08 13:37:00,983 - INFO - Updated vocab_size to: 6
2025-12-08 13:37:00,983 - INFO - Creating ELMo BiLM model...
2025-12-08 13:37:01,888 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:37:01,892 - INFO - Creating data loader...
2025-12-08 13:37:01,892 - ERROR - Failed to create data loader: unhashable type: 'list'
2025-12-08 13:37:01,892 - INFO - Please check if the data file exists and run preprocessing if needed
2025-12-08 13:37:50,233 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:37:50,298 - INFO - Using device: cuda
2025-12-08 13:37:50,314 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:37:50,315 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:37:52,267 - INFO - Loaded vocabulary: 6 words
2025-12-08 13:37:52,267 - INFO - Updated vocab_size to: 6
2025-12-08 13:37:52,267 - INFO - Creating ELMo BiLM model...
2025-12-08 13:37:53,112 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1
2025-12-08 13:37:53,114 - INFO - Creating data loader...
2025-12-08 13:37:53,114 - ERROR - Failed to create data loader: unhashable type: 'list'
2025-12-08 13:37:53,114 - INFO - Please check if the data file exists and run preprocessing if needed
2025-12-08 13:40:04,167 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:40:04,233 - INFO - Using device: cuda
2025-12-08 13:40:04,249 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:40:04,249 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:40:06,235 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 13:40:06,336 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 13:40:06,336 - INFO - Creating ELMo BiLM model...
2025-12-08 13:40:35,614 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:40:35,616 - INFO - Creating data loader...
2025-12-08 13:40:35,899 - INFO - Data loader created successfully
2025-12-08 13:40:35,899 - INFO - Starting training...
2025-12-08 13:40:35,899 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:40:35,899 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_134035
2025-12-08 13:41:50,934 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:41:51,040 - INFO - Using device: cuda
2025-12-08 13:41:51,057 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:41:51,057 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:41:53,025 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 13:41:53,126 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 13:41:53,126 - INFO - Creating ELMo BiLM model...
2025-12-08 13:42:22,754 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:42:22,755 - INFO - Creating data loader...
2025-12-08 13:42:23,057 - INFO - Data loader created successfully
2025-12-08 13:42:23,057 - INFO - Starting training...
2025-12-08 13:42:23,057 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:42:23,057 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_134222
2025-12-08 13:42:23,542 - ERROR - Error in batch 0: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.80 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 81.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,556 - ERROR - Error in batch 1: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,569 - ERROR - Error in batch 2: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,582 - ERROR - Error in batch 3: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,595 - ERROR - Error in batch 4: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,608 - ERROR - Error in batch 5: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,621 - ERROR - Error in batch 6: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,634 - ERROR - Error in batch 7: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,647 - ERROR - Error in batch 8: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,660 - ERROR - Error in batch 9: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,673 - ERROR - Error in batch 10: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,686 - ERROR - Error in batch 11: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,699 - ERROR - Error in batch 12: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,712 - ERROR - Error in batch 13: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,725 - ERROR - Error in batch 14: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,737 - ERROR - Error in batch 15: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,750 - ERROR - Error in batch 16: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,764 - ERROR - Error in batch 17: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,777 - ERROR - Error in batch 18: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,789 - ERROR - Error in batch 19: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,802 - ERROR - Error in batch 20: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,815 - ERROR - Error in batch 21: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,828 - ERROR - Error in batch 22: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,841 - ERROR - Error in batch 23: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,852 - ERROR - Error in batch 24: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,865 - ERROR - Error in batch 25: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,878 - ERROR - Error in batch 26: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,892 - ERROR - Error in batch 27: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,905 - ERROR - Error in batch 28: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,915 - ERROR - Error in batch 29: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,927 - ERROR - Error in batch 30: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,940 - ERROR - Error in batch 31: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:23,957 - ERROR - Error in batch 32: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,032 - ERROR - Error in batch 33: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,042 - ERROR - Error in batch 34: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,053 - ERROR - Error in batch 35: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,064 - ERROR - Error in batch 36: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,076 - ERROR - Error in batch 37: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,086 - ERROR - Error in batch 38: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,097 - ERROR - Error in batch 39: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,109 - ERROR - Error in batch 40: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,122 - ERROR - Error in batch 41: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,132 - ERROR - Error in batch 42: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,145 - ERROR - Error in batch 43: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,156 - ERROR - Error in batch 44: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,166 - ERROR - Error in batch 45: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,178 - ERROR - Error in batch 46: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,189 - ERROR - Error in batch 47: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,202 - ERROR - Error in batch 48: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,213 - ERROR - Error in batch 49: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,225 - ERROR - Error in batch 50: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,236 - ERROR - Error in batch 51: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,247 - ERROR - Error in batch 52: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,259 - ERROR - Error in batch 53: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,270 - ERROR - Error in batch 54: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,280 - ERROR - Error in batch 55: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,291 - ERROR - Error in batch 56: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,304 - ERROR - Error in batch 57: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,315 - ERROR - Error in batch 58: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,326 - ERROR - Error in batch 59: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,336 - ERROR - Error in batch 60: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,349 - ERROR - Error in batch 61: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,359 - ERROR - Error in batch 62: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,371 - ERROR - Error in batch 63: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,383 - ERROR - Error in batch 64: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,393 - ERROR - Error in batch 65: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,404 - ERROR - Error in batch 66: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,415 - ERROR - Error in batch 67: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,427 - ERROR - Error in batch 68: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,438 - ERROR - Error in batch 69: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,449 - ERROR - Error in batch 70: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,461 - ERROR - Error in batch 71: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,471 - ERROR - Error in batch 72: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,482 - ERROR - Error in batch 73: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,495 - ERROR - Error in batch 74: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,505 - ERROR - Error in batch 75: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,518 - ERROR - Error in batch 76: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,529 - ERROR - Error in batch 77: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,539 - ERROR - Error in batch 78: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,551 - ERROR - Error in batch 79: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,562 - ERROR - Error in batch 80: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,574 - ERROR - Error in batch 81: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,587 - ERROR - Error in batch 82: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,599 - ERROR - Error in batch 83: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,613 - ERROR - Error in batch 84: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,626 - ERROR - Error in batch 85: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,640 - ERROR - Error in batch 86: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,653 - ERROR - Error in batch 87: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,667 - ERROR - Error in batch 88: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,679 - ERROR - Error in batch 89: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,692 - ERROR - Error in batch 90: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,704 - ERROR - Error in batch 91: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,717 - ERROR - Error in batch 92: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,730 - ERROR - Error in batch 93: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,743 - ERROR - Error in batch 94: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,756 - ERROR - Error in batch 95: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,769 - ERROR - Error in batch 96: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,783 - ERROR - Error in batch 97: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,796 - ERROR - Error in batch 98: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,808 - ERROR - Error in batch 99: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,821 - ERROR - Error in batch 100: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,834 - ERROR - Error in batch 101: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,847 - ERROR - Error in batch 102: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,860 - ERROR - Error in batch 103: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,873 - ERROR - Error in batch 104: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,886 - ERROR - Error in batch 105: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,899 - ERROR - Error in batch 106: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,912 - ERROR - Error in batch 107: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,924 - ERROR - Error in batch 108: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,937 - ERROR - Error in batch 109: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,950 - ERROR - Error in batch 110: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,963 - ERROR - Error in batch 111: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,976 - ERROR - Error in batch 112: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:24,989 - ERROR - Error in batch 113: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,001 - ERROR - Error in batch 114: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,014 - ERROR - Error in batch 115: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,027 - ERROR - Error in batch 116: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,040 - ERROR - Error in batch 117: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,055 - ERROR - Error in batch 118: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,128 - ERROR - Error in batch 119: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,140 - ERROR - Error in batch 120: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,153 - ERROR - Error in batch 121: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,166 - ERROR - Error in batch 122: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,180 - ERROR - Error in batch 123: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,192 - ERROR - Error in batch 124: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,205 - ERROR - Error in batch 125: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,218 - ERROR - Error in batch 126: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,231 - ERROR - Error in batch 127: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,245 - ERROR - Error in batch 128: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,258 - ERROR - Error in batch 129: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,271 - ERROR - Error in batch 130: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,284 - ERROR - Error in batch 131: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,296 - ERROR - Error in batch 132: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,309 - ERROR - Error in batch 133: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,321 - ERROR - Error in batch 134: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,331 - ERROR - Error in batch 135: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,343 - ERROR - Error in batch 136: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,354 - ERROR - Error in batch 137: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,364 - ERROR - Error in batch 138: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,377 - ERROR - Error in batch 139: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,390 - ERROR - Error in batch 140: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,400 - ERROR - Error in batch 141: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,413 - ERROR - Error in batch 142: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,424 - ERROR - Error in batch 143: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,435 - ERROR - Error in batch 144: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,448 - ERROR - Error in batch 145: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,461 - ERROR - Error in batch 146: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,474 - ERROR - Error in batch 147: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,484 - ERROR - Error in batch 148: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,495 - ERROR - Error in batch 149: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,506 - ERROR - Error in batch 150: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,518 - ERROR - Error in batch 151: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,530 - ERROR - Error in batch 152: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,540 - ERROR - Error in batch 153: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,552 - ERROR - Error in batch 154: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,563 - ERROR - Error in batch 155: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,574 - ERROR - Error in batch 156: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,586 - ERROR - Error in batch 157: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,598 - ERROR - Error in batch 158: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,611 - ERROR - Error in batch 159: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,624 - ERROR - Error in batch 160: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,637 - ERROR - Error in batch 161: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,650 - ERROR - Error in batch 162: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,663 - ERROR - Error in batch 163: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,676 - ERROR - Error in batch 164: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,688 - ERROR - Error in batch 165: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,701 - ERROR - Error in batch 166: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,714 - ERROR - Error in batch 167: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,727 - ERROR - Error in batch 168: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,740 - ERROR - Error in batch 169: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,753 - ERROR - Error in batch 170: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,766 - ERROR - Error in batch 171: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,779 - ERROR - Error in batch 172: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,792 - ERROR - Error in batch 173: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,805 - ERROR - Error in batch 174: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,818 - ERROR - Error in batch 175: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,831 - ERROR - Error in batch 176: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,844 - ERROR - Error in batch 177: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,857 - ERROR - Error in batch 178: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,870 - ERROR - Error in batch 179: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,883 - ERROR - Error in batch 180: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,896 - ERROR - Error in batch 181: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,909 - ERROR - Error in batch 182: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,922 - ERROR - Error in batch 183: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,935 - ERROR - Error in batch 184: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,947 - ERROR - Error in batch 185: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,960 - ERROR - Error in batch 186: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,973 - ERROR - Error in batch 187: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,986 - ERROR - Error in batch 188: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:25,999 - ERROR - Error in batch 189: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,012 - ERROR - Error in batch 190: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,025 - ERROR - Error in batch 191: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,038 - ERROR - Error in batch 192: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,050 - ERROR - Error in batch 193: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,063 - ERROR - Error in batch 194: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,076 - ERROR - Error in batch 195: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,088 - ERROR - Error in batch 196: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,101 - ERROR - Error in batch 197: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,114 - ERROR - Error in batch 198: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,127 - ERROR - Error in batch 199: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,140 - ERROR - Error in batch 200: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,154 - ERROR - Error in batch 201: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,232 - ERROR - Error in batch 202: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,244 - ERROR - Error in batch 203: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,257 - ERROR - Error in batch 204: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,270 - ERROR - Error in batch 205: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,283 - ERROR - Error in batch 206: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,296 - ERROR - Error in batch 207: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,309 - ERROR - Error in batch 208: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,322 - ERROR - Error in batch 209: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,335 - ERROR - Error in batch 210: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,348 - ERROR - Error in batch 211: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,361 - ERROR - Error in batch 212: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,374 - ERROR - Error in batch 213: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,387 - ERROR - Error in batch 214: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,400 - ERROR - Error in batch 215: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,414 - ERROR - Error in batch 216: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,427 - ERROR - Error in batch 217: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,440 - ERROR - Error in batch 218: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,453 - ERROR - Error in batch 219: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,466 - ERROR - Error in batch 220: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,479 - ERROR - Error in batch 221: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,491 - ERROR - Error in batch 222: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,502 - ERROR - Error in batch 223: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,515 - ERROR - Error in batch 224: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,528 - ERROR - Error in batch 225: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,540 - ERROR - Error in batch 226: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,553 - ERROR - Error in batch 227: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,566 - ERROR - Error in batch 228: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,578 - ERROR - Error in batch 229: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,591 - ERROR - Error in batch 230: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,604 - ERROR - Error in batch 231: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,616 - ERROR - Error in batch 232: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,628 - ERROR - Error in batch 233: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,638 - ERROR - Error in batch 234: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,650 - ERROR - Error in batch 235: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,660 - ERROR - Error in batch 236: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,672 - ERROR - Error in batch 237: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,683 - ERROR - Error in batch 238: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,693 - ERROR - Error in batch 239: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,705 - ERROR - Error in batch 240: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,717 - ERROR - Error in batch 241: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,728 - ERROR - Error in batch 242: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,738 - ERROR - Error in batch 243: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,751 - ERROR - Error in batch 244: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,764 - ERROR - Error in batch 245: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,775 - ERROR - Error in batch 246: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,785 - ERROR - Error in batch 247: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,796 - ERROR - Error in batch 248: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,807 - ERROR - Error in batch 249: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,819 - ERROR - Error in batch 250: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,830 - ERROR - Error in batch 251: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,840 - ERROR - Error in batch 252: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,852 - ERROR - Error in batch 253: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,863 - ERROR - Error in batch 254: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,874 - ERROR - Error in batch 255: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,885 - ERROR - Error in batch 256: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,896 - ERROR - Error in batch 257: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,906 - ERROR - Error in batch 258: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,917 - ERROR - Error in batch 259: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,928 - ERROR - Error in batch 260: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,940 - ERROR - Error in batch 261: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,951 - ERROR - Error in batch 262: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,964 - ERROR - Error in batch 263: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,977 - ERROR - Error in batch 264: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,987 - ERROR - Error in batch 265: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:26,998 - ERROR - Error in batch 266: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,012 - ERROR - Error in batch 267: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,025 - ERROR - Error in batch 268: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,036 - ERROR - Error in batch 269: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,048 - ERROR - Error in batch 270: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,059 - ERROR - Error in batch 271: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,071 - ERROR - Error in batch 272: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,081 - ERROR - Error in batch 273: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,093 - ERROR - Error in batch 274: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,106 - ERROR - Error in batch 275: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,116 - ERROR - Error in batch 276: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,127 - ERROR - Error in batch 277: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,138 - ERROR - Error in batch 278: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,150 - ERROR - Error in batch 279: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,160 - ERROR - Error in batch 280: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,173 - ERROR - Error in batch 281: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,186 - ERROR - Error in batch 282: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,197 - ERROR - Error in batch 283: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,208 - ERROR - Error in batch 284: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,220 - ERROR - Error in batch 285: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,231 - ERROR - Error in batch 286: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,242 - ERROR - Error in batch 287: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,253 - ERROR - Error in batch 288: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,329 - ERROR - Error in batch 289: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,342 - ERROR - Error in batch 290: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,354 - ERROR - Error in batch 291: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,365 - ERROR - Error in batch 292: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,376 - ERROR - Error in batch 293: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,386 - ERROR - Error in batch 294: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,399 - ERROR - Error in batch 295: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,409 - ERROR - Error in batch 296: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,420 - ERROR - Error in batch 297: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,433 - ERROR - Error in batch 298: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,443 - ERROR - Error in batch 299: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,455 - ERROR - Error in batch 300: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,465 - ERROR - Error in batch 301: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,477 - ERROR - Error in batch 302: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,488 - ERROR - Error in batch 303: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,498 - ERROR - Error in batch 304: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,509 - ERROR - Error in batch 305: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,520 - ERROR - Error in batch 306: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,533 - ERROR - Error in batch 307: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,547 - ERROR - Error in batch 308: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,560 - ERROR - Error in batch 309: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,573 - ERROR - Error in batch 310: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,585 - ERROR - Error in batch 311: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,595 - ERROR - Error in batch 312: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,606 - ERROR - Error in batch 313: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,617 - ERROR - Error in batch 314: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,628 - ERROR - Error in batch 315: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,640 - ERROR - Error in batch 316: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,651 - ERROR - Error in batch 317: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,661 - ERROR - Error in batch 318: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,674 - ERROR - Error in batch 319: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,687 - ERROR - Error in batch 320: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,697 - ERROR - Error in batch 321: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,709 - ERROR - Error in batch 322: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,719 - ERROR - Error in batch 323: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,732 - ERROR - Error in batch 324: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,742 - ERROR - Error in batch 325: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,755 - ERROR - Error in batch 326: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,765 - ERROR - Error in batch 327: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,778 - ERROR - Error in batch 328: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,788 - ERROR - Error in batch 329: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,799 - ERROR - Error in batch 330: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,813 - ERROR - Error in batch 331: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,823 - ERROR - Error in batch 332: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,835 - ERROR - Error in batch 333: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,847 - ERROR - Error in batch 334: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,858 - ERROR - Error in batch 335: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,871 - ERROR - Error in batch 336: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,884 - ERROR - Error in batch 337: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,895 - ERROR - Error in batch 338: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,907 - ERROR - Error in batch 339: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,917 - ERROR - Error in batch 340: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,928 - ERROR - Error in batch 341: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,940 - ERROR - Error in batch 342: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,951 - ERROR - Error in batch 343: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,963 - ERROR - Error in batch 344: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,974 - ERROR - Error in batch 345: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,984 - ERROR - Error in batch 346: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:27,995 - ERROR - Error in batch 347: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,008 - ERROR - Error in batch 348: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,018 - ERROR - Error in batch 349: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,029 - ERROR - Error in batch 350: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,041 - ERROR - Error in batch 351: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,052 - ERROR - Error in batch 352: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,063 - ERROR - Error in batch 353: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,075 - ERROR - Error in batch 354: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,086 - ERROR - Error in batch 355: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,097 - ERROR - Error in batch 356: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,107 - ERROR - Error in batch 357: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,118 - ERROR - Error in batch 358: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,129 - ERROR - Error in batch 359: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,141 - ERROR - Error in batch 360: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,152 - ERROR - Error in batch 361: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,162 - ERROR - Error in batch 362: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,175 - ERROR - Error in batch 363: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,185 - ERROR - Error in batch 364: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,196 - ERROR - Error in batch 365: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,207 - ERROR - Error in batch 366: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,220 - ERROR - Error in batch 367: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,231 - ERROR - Error in batch 368: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,244 - ERROR - Error in batch 369: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,254 - ERROR - Error in batch 370: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,266 - ERROR - Error in batch 371: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,277 - ERROR - Error in batch 372: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,287 - ERROR - Error in batch 373: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,299 - ERROR - Error in batch 374: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,312 - ERROR - Error in batch 375: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,324 - ERROR - Error in batch 376: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,335 - ERROR - Error in batch 377: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,346 - ERROR - Error in batch 378: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,360 - ERROR - Error in batch 379: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,431 - ERROR - Error in batch 380: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,444 - ERROR - Error in batch 381: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,455 - ERROR - Error in batch 382: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,465 - ERROR - Error in batch 383: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,477 - ERROR - Error in batch 384: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,489 - ERROR - Error in batch 385: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,499 - ERROR - Error in batch 386: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,511 - ERROR - Error in batch 387: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,522 - ERROR - Error in batch 388: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,533 - ERROR - Error in batch 389: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,544 - ERROR - Error in batch 390: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,555 - ERROR - Error in batch 391: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,568 - ERROR - Error in batch 392: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,578 - ERROR - Error in batch 393: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,589 - ERROR - Error in batch 394: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,600 - ERROR - Error in batch 395: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,611 - ERROR - Error in batch 396: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,622 - ERROR - Error in batch 397: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,633 - ERROR - Error in batch 398: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,646 - ERROR - Error in batch 399: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,657 - ERROR - Error in batch 400: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,668 - ERROR - Error in batch 401: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,681 - ERROR - Error in batch 402: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,693 - ERROR - Error in batch 403: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,705 - ERROR - Error in batch 404: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,715 - ERROR - Error in batch 405: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,726 - ERROR - Error in batch 406: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,737 - ERROR - Error in batch 407: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,748 - ERROR - Error in batch 408: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,759 - ERROR - Error in batch 409: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,770 - ERROR - Error in batch 410: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,781 - ERROR - Error in batch 411: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,792 - ERROR - Error in batch 412: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,804 - ERROR - Error in batch 413: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,816 - ERROR - Error in batch 414: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,829 - ERROR - Error in batch 415: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,841 - ERROR - Error in batch 416: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,853 - ERROR - Error in batch 417: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,866 - ERROR - Error in batch 418: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,879 - ERROR - Error in batch 419: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,889 - ERROR - Error in batch 420: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,900 - ERROR - Error in batch 421: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,912 - ERROR - Error in batch 422: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,925 - ERROR - Error in batch 423: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,938 - ERROR - Error in batch 424: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,951 - ERROR - Error in batch 425: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,965 - ERROR - Error in batch 426: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,978 - ERROR - Error in batch 427: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,988 - ERROR - Error in batch 428: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:28,999 - ERROR - Error in batch 429: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,010 - ERROR - Error in batch 430: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,023 - ERROR - Error in batch 431: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,033 - ERROR - Error in batch 432: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,044 - ERROR - Error in batch 433: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,055 - ERROR - Error in batch 434: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,066 - ERROR - Error in batch 435: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,079 - ERROR - Error in batch 436: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,089 - ERROR - Error in batch 437: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,100 - ERROR - Error in batch 438: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,112 - ERROR - Error in batch 439: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,122 - ERROR - Error in batch 440: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,133 - ERROR - Error in batch 441: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,144 - ERROR - Error in batch 442: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,157 - ERROR - Error in batch 443: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,170 - ERROR - Error in batch 444: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,183 - ERROR - Error in batch 445: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,196 - ERROR - Error in batch 446: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,207 - ERROR - Error in batch 447: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,220 - ERROR - Error in batch 448: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,233 - ERROR - Error in batch 449: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,246 - ERROR - Error in batch 450: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,259 - ERROR - Error in batch 451: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,272 - ERROR - Error in batch 452: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,284 - ERROR - Error in batch 453: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,296 - ERROR - Error in batch 454: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,309 - ERROR - Error in batch 455: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,322 - ERROR - Error in batch 456: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,334 - ERROR - Error in batch 457: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,346 - ERROR - Error in batch 458: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,359 - ERROR - Error in batch 459: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,372 - ERROR - Error in batch 460: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,385 - ERROR - Error in batch 461: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,398 - ERROR - Error in batch 462: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,411 - ERROR - Error in batch 463: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,424 - ERROR - Error in batch 464: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,437 - ERROR - Error in batch 465: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,451 - ERROR - Error in batch 466: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,464 - ERROR - Error in batch 467: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,535 - ERROR - Error in batch 468: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,547 - ERROR - Error in batch 469: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,560 - ERROR - Error in batch 470: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,573 - ERROR - Error in batch 471: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,586 - ERROR - Error in batch 472: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,599 - ERROR - Error in batch 473: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,612 - ERROR - Error in batch 474: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,625 - ERROR - Error in batch 475: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,638 - ERROR - Error in batch 476: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,651 - ERROR - Error in batch 477: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,663 - ERROR - Error in batch 478: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,674 - ERROR - Error in batch 479: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,687 - ERROR - Error in batch 480: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,700 - ERROR - Error in batch 481: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,712 - ERROR - Error in batch 482: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,725 - ERROR - Error in batch 483: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,738 - ERROR - Error in batch 484: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,751 - ERROR - Error in batch 485: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,763 - ERROR - Error in batch 486: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,776 - ERROR - Error in batch 487: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,789 - ERROR - Error in batch 488: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,802 - ERROR - Error in batch 489: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,814 - ERROR - Error in batch 490: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,827 - ERROR - Error in batch 491: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,840 - ERROR - Error in batch 492: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,852 - ERROR - Error in batch 493: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,865 - ERROR - Error in batch 494: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,878 - ERROR - Error in batch 495: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,890 - ERROR - Error in batch 496: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,903 - ERROR - Error in batch 497: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,916 - ERROR - Error in batch 498: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,929 - ERROR - Error in batch 499: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,943 - ERROR - Error in batch 500: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,955 - ERROR - Error in batch 501: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,967 - ERROR - Error in batch 502: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,980 - ERROR - Error in batch 503: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:29,992 - ERROR - Error in batch 504: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,005 - ERROR - Error in batch 505: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,018 - ERROR - Error in batch 506: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,031 - ERROR - Error in batch 507: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,045 - ERROR - Error in batch 508: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,058 - ERROR - Error in batch 509: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,071 - ERROR - Error in batch 510: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,084 - ERROR - Error in batch 511: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,096 - ERROR - Error in batch 512: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,109 - ERROR - Error in batch 513: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,123 - ERROR - Error in batch 514: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,136 - ERROR - Error in batch 515: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,150 - ERROR - Error in batch 516: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,160 - ERROR - Error in batch 517: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,173 - ERROR - Error in batch 518: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,186 - ERROR - Error in batch 519: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,196 - ERROR - Error in batch 520: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,208 - ERROR - Error in batch 521: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,218 - ERROR - Error in batch 522: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,231 - ERROR - Error in batch 523: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,242 - ERROR - Error in batch 524: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,253 - ERROR - Error in batch 525: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,263 - ERROR - Error in batch 526: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,276 - ERROR - Error in batch 527: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,286 - ERROR - Error in batch 528: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,299 - ERROR - Error in batch 529: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,309 - ERROR - Error in batch 530: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,320 - ERROR - Error in batch 531: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,333 - ERROR - Error in batch 532: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,343 - ERROR - Error in batch 533: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,355 - ERROR - Error in batch 534: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,366 - ERROR - Error in batch 535: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,378 - ERROR - Error in batch 536: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,390 - ERROR - Error in batch 537: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,400 - ERROR - Error in batch 538: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,412 - ERROR - Error in batch 539: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,425 - ERROR - Error in batch 540: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,439 - ERROR - Error in batch 541: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,452 - ERROR - Error in batch 542: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,464 - ERROR - Error in batch 543: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,474 - ERROR - Error in batch 544: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,487 - ERROR - Error in batch 545: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,497 - ERROR - Error in batch 546: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,508 - ERROR - Error in batch 547: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,520 - ERROR - Error in batch 548: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,532 - ERROR - Error in batch 549: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,542 - ERROR - Error in batch 550: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,554 - ERROR - Error in batch 551: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,569 - ERROR - Error in batch 552: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,644 - ERROR - Error in batch 553: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:42:30,657 - ERROR - Error in batch 554: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:12,049 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:49:12,120 - INFO - Using device: cuda
2025-12-08 13:49:12,139 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:49:12,140 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:49:14,217 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 13:49:14,317 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 13:49:14,317 - INFO - Creating ELMo BiLM model...
2025-12-08 13:49:43,612 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:49:43,613 - INFO - Creating data loader...
2025-12-08 13:49:43,897 - INFO - Data loader created successfully
2025-12-08 13:49:43,898 - INFO - Starting training...
2025-12-08 13:49:43,898 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:49:43,898 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_134943
2025-12-08 13:49:44,369 - ERROR - Error in batch 0: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.80 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 81.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,383 - ERROR - Error in batch 1: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,397 - ERROR - Error in batch 2: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,409 - ERROR - Error in batch 3: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,422 - ERROR - Error in batch 4: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,435 - ERROR - Error in batch 5: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,447 - ERROR - Error in batch 6: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,460 - ERROR - Error in batch 7: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,474 - ERROR - Error in batch 8: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,486 - ERROR - Error in batch 9: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,499 - ERROR - Error in batch 10: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,512 - ERROR - Error in batch 11: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,522 - ERROR - Error in batch 12: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,534 - ERROR - Error in batch 13: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,545 - ERROR - Error in batch 14: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,558 - ERROR - Error in batch 15: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,571 - ERROR - Error in batch 16: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,582 - ERROR - Error in batch 17: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,592 - ERROR - Error in batch 18: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,606 - ERROR - Error in batch 19: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,619 - ERROR - Error in batch 20: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,630 - ERROR - Error in batch 21: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,641 - ERROR - Error in batch 22: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,652 - ERROR - Error in batch 23: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,665 - ERROR - Error in batch 24: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,676 - ERROR - Error in batch 25: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,687 - ERROR - Error in batch 26: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,698 - ERROR - Error in batch 27: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,710 - ERROR - Error in batch 28: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,723 - ERROR - Error in batch 29: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,736 - ERROR - Error in batch 30: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,750 - ERROR - Error in batch 31: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,763 - ERROR - Error in batch 32: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,776 - ERROR - Error in batch 33: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,787 - ERROR - Error in batch 34: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,800 - ERROR - Error in batch 35: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,813 - ERROR - Error in batch 36: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,823 - ERROR - Error in batch 37: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,837 - ERROR - Error in batch 38: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,850 - ERROR - Error in batch 39: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,862 - ERROR - Error in batch 40: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,874 - ERROR - Error in batch 41: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,885 - ERROR - Error in batch 42: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,895 - ERROR - Error in batch 43: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,907 - ERROR - Error in batch 44: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,920 - ERROR - Error in batch 45: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,931 - ERROR - Error in batch 46: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,943 - ERROR - Error in batch 47: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:44,955 - ERROR - Error in batch 48: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,029 - ERROR - Error in batch 49: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,042 - ERROR - Error in batch 50: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,055 - ERROR - Error in batch 51: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,066 - ERROR - Error in batch 52: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,079 - ERROR - Error in batch 53: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,092 - ERROR - Error in batch 54: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,104 - ERROR - Error in batch 55: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,117 - ERROR - Error in batch 56: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,129 - ERROR - Error in batch 57: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,142 - ERROR - Error in batch 58: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,152 - ERROR - Error in batch 59: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,164 - ERROR - Error in batch 60: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,174 - ERROR - Error in batch 61: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,186 - ERROR - Error in batch 62: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,198 - ERROR - Error in batch 63: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,211 - ERROR - Error in batch 64: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,224 - ERROR - Error in batch 65: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,235 - ERROR - Error in batch 66: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,248 - ERROR - Error in batch 67: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,261 - ERROR - Error in batch 68: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,271 - ERROR - Error in batch 69: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,282 - ERROR - Error in batch 70: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,295 - ERROR - Error in batch 71: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,308 - ERROR - Error in batch 72: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,319 - ERROR - Error in batch 73: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,332 - ERROR - Error in batch 74: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,344 - ERROR - Error in batch 75: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,355 - ERROR - Error in batch 76: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,366 - ERROR - Error in batch 77: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,379 - ERROR - Error in batch 78: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,390 - ERROR - Error in batch 79: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,401 - ERROR - Error in batch 80: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,413 - ERROR - Error in batch 81: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,424 - ERROR - Error in batch 82: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,435 - ERROR - Error in batch 83: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,448 - ERROR - Error in batch 84: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,459 - ERROR - Error in batch 85: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,472 - ERROR - Error in batch 86: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,485 - ERROR - Error in batch 87: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,498 - ERROR - Error in batch 88: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,511 - ERROR - Error in batch 89: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,524 - ERROR - Error in batch 90: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,537 - ERROR - Error in batch 91: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,550 - ERROR - Error in batch 92: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,561 - ERROR - Error in batch 93: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,574 - ERROR - Error in batch 94: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,586 - ERROR - Error in batch 95: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,596 - ERROR - Error in batch 96: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,607 - ERROR - Error in batch 97: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,619 - ERROR - Error in batch 98: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,631 - ERROR - Error in batch 99: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,642 - ERROR - Error in batch 100: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,653 - ERROR - Error in batch 101: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,663 - ERROR - Error in batch 102: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,674 - ERROR - Error in batch 103: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,688 - ERROR - Error in batch 104: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,701 - ERROR - Error in batch 105: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,714 - ERROR - Error in batch 106: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,727 - ERROR - Error in batch 107: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,738 - ERROR - Error in batch 108: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,751 - ERROR - Error in batch 109: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,764 - ERROR - Error in batch 110: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,776 - ERROR - Error in batch 111: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,786 - ERROR - Error in batch 112: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,800 - ERROR - Error in batch 113: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,813 - ERROR - Error in batch 114: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,827 - ERROR - Error in batch 115: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,840 - ERROR - Error in batch 116: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,853 - ERROR - Error in batch 117: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,867 - ERROR - Error in batch 118: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,879 - ERROR - Error in batch 119: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,890 - ERROR - Error in batch 120: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,904 - ERROR - Error in batch 121: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,917 - ERROR - Error in batch 122: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,930 - ERROR - Error in batch 123: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,943 - ERROR - Error in batch 124: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,956 - ERROR - Error in batch 125: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,969 - ERROR - Error in batch 126: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,980 - ERROR - Error in batch 127: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:45,992 - ERROR - Error in batch 128: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,005 - ERROR - Error in batch 129: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,018 - ERROR - Error in batch 130: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,029 - ERROR - Error in batch 131: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,040 - ERROR - Error in batch 132: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,051 - ERROR - Error in batch 133: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,064 - ERROR - Error in batch 134: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,142 - ERROR - Error in batch 135: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,154 - ERROR - Error in batch 136: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,164 - ERROR - Error in batch 137: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,177 - ERROR - Error in batch 138: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,188 - ERROR - Error in batch 139: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,201 - ERROR - Error in batch 140: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,213 - ERROR - Error in batch 141: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,226 - ERROR - Error in batch 142: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,239 - ERROR - Error in batch 143: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,250 - ERROR - Error in batch 144: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,263 - ERROR - Error in batch 145: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,276 - ERROR - Error in batch 146: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,286 - ERROR - Error in batch 147: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,297 - ERROR - Error in batch 148: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,308 - ERROR - Error in batch 149: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,319 - ERROR - Error in batch 150: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,333 - ERROR - Error in batch 151: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,345 - ERROR - Error in batch 152: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,358 - ERROR - Error in batch 153: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,371 - ERROR - Error in batch 154: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,384 - ERROR - Error in batch 155: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,397 - ERROR - Error in batch 156: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,410 - ERROR - Error in batch 157: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,423 - ERROR - Error in batch 158: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,434 - ERROR - Error in batch 159: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,447 - ERROR - Error in batch 160: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,459 - ERROR - Error in batch 161: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,470 - ERROR - Error in batch 162: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,481 - ERROR - Error in batch 163: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,494 - ERROR - Error in batch 164: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,507 - ERROR - Error in batch 165: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,520 - ERROR - Error in batch 166: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,532 - ERROR - Error in batch 167: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,545 - ERROR - Error in batch 168: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,559 - ERROR - Error in batch 169: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,572 - ERROR - Error in batch 170: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,584 - ERROR - Error in batch 171: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,594 - ERROR - Error in batch 172: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,605 - ERROR - Error in batch 173: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,616 - ERROR - Error in batch 174: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,629 - ERROR - Error in batch 175: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,639 - ERROR - Error in batch 176: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,653 - ERROR - Error in batch 177: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,664 - ERROR - Error in batch 178: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,675 - ERROR - Error in batch 179: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,688 - ERROR - Error in batch 180: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,701 - ERROR - Error in batch 181: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,714 - ERROR - Error in batch 182: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,725 - ERROR - Error in batch 183: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,737 - ERROR - Error in batch 184: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,751 - ERROR - Error in batch 185: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,763 - ERROR - Error in batch 186: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,776 - ERROR - Error in batch 187: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,787 - ERROR - Error in batch 188: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,797 - ERROR - Error in batch 189: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,809 - ERROR - Error in batch 190: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,822 - ERROR - Error in batch 191: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,834 - ERROR - Error in batch 192: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,847 - ERROR - Error in batch 193: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,860 - ERROR - Error in batch 194: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,871 - ERROR - Error in batch 195: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,883 - ERROR - Error in batch 196: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,894 - ERROR - Error in batch 197: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,907 - ERROR - Error in batch 198: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,920 - ERROR - Error in batch 199: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,934 - ERROR - Error in batch 200: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,947 - ERROR - Error in batch 201: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,961 - ERROR - Error in batch 202: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,972 - ERROR - Error in batch 203: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,986 - ERROR - Error in batch 204: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:46,999 - ERROR - Error in batch 205: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,012 - ERROR - Error in batch 206: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,025 - ERROR - Error in batch 207: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,036 - ERROR - Error in batch 208: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,046 - ERROR - Error in batch 209: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,059 - ERROR - Error in batch 210: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,072 - ERROR - Error in batch 211: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,085 - ERROR - Error in batch 212: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,098 - ERROR - Error in batch 213: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,111 - ERROR - Error in batch 214: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,124 - ERROR - Error in batch 215: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,137 - ERROR - Error in batch 216: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,149 - ERROR - Error in batch 217: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,163 - ERROR - Error in batch 218: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,237 - ERROR - Error in batch 219: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,247 - ERROR - Error in batch 220: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,259 - ERROR - Error in batch 221: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,272 - ERROR - Error in batch 222: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,285 - ERROR - Error in batch 223: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,297 - ERROR - Error in batch 224: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,309 - ERROR - Error in batch 225: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,322 - ERROR - Error in batch 226: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,333 - ERROR - Error in batch 227: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,344 - ERROR - Error in batch 228: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,354 - ERROR - Error in batch 229: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,366 - ERROR - Error in batch 230: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,379 - ERROR - Error in batch 231: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,393 - ERROR - Error in batch 232: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,406 - ERROR - Error in batch 233: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,420 - ERROR - Error in batch 234: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,434 - ERROR - Error in batch 235: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,444 - ERROR - Error in batch 236: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,456 - ERROR - Error in batch 237: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,467 - ERROR - Error in batch 238: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,480 - ERROR - Error in batch 239: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,491 - ERROR - Error in batch 240: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,504 - ERROR - Error in batch 241: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,515 - ERROR - Error in batch 242: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,526 - ERROR - Error in batch 243: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,537 - ERROR - Error in batch 244: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,547 - ERROR - Error in batch 245: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,559 - ERROR - Error in batch 246: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,572 - ERROR - Error in batch 247: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,585 - ERROR - Error in batch 248: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,596 - ERROR - Error in batch 249: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,606 - ERROR - Error in batch 250: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,617 - ERROR - Error in batch 251: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,629 - ERROR - Error in batch 252: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,642 - ERROR - Error in batch 253: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,655 - ERROR - Error in batch 254: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,668 - ERROR - Error in batch 255: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,681 - ERROR - Error in batch 256: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,694 - ERROR - Error in batch 257: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,707 - ERROR - Error in batch 258: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,720 - ERROR - Error in batch 259: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,733 - ERROR - Error in batch 260: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,746 - ERROR - Error in batch 261: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,757 - ERROR - Error in batch 262: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,771 - ERROR - Error in batch 263: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,784 - ERROR - Error in batch 264: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,797 - ERROR - Error in batch 265: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,807 - ERROR - Error in batch 266: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,818 - ERROR - Error in batch 267: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,830 - ERROR - Error in batch 268: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,841 - ERROR - Error in batch 269: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,852 - ERROR - Error in batch 270: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,864 - ERROR - Error in batch 271: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,877 - ERROR - Error in batch 272: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,890 - ERROR - Error in batch 273: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,902 - ERROR - Error in batch 274: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,913 - ERROR - Error in batch 275: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,926 - ERROR - Error in batch 276: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,939 - ERROR - Error in batch 277: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,952 - ERROR - Error in batch 278: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,966 - ERROR - Error in batch 279: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,977 - ERROR - Error in batch 280: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,988 - ERROR - Error in batch 281: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:47,999 - ERROR - Error in batch 282: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,011 - ERROR - Error in batch 283: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,024 - ERROR - Error in batch 284: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,037 - ERROR - Error in batch 285: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,050 - ERROR - Error in batch 286: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,063 - ERROR - Error in batch 287: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,076 - ERROR - Error in batch 288: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,089 - ERROR - Error in batch 289: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,102 - ERROR - Error in batch 290: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,112 - ERROR - Error in batch 291: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,126 - ERROR - Error in batch 292: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,137 - ERROR - Error in batch 293: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,147 - ERROR - Error in batch 294: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,159 - ERROR - Error in batch 295: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,171 - ERROR - Error in batch 296: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,181 - ERROR - Error in batch 297: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,192 - ERROR - Error in batch 298: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,204 - ERROR - Error in batch 299: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,215 - ERROR - Error in batch 300: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,226 - ERROR - Error in batch 301: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,240 - ERROR - Error in batch 302: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,254 - ERROR - Error in batch 303: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,327 - ERROR - Error in batch 304: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,340 - ERROR - Error in batch 305: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,353 - ERROR - Error in batch 306: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,363 - ERROR - Error in batch 307: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,374 - ERROR - Error in batch 308: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,385 - ERROR - Error in batch 309: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,399 - ERROR - Error in batch 310: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,409 - ERROR - Error in batch 311: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,422 - ERROR - Error in batch 312: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,435 - ERROR - Error in batch 313: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,448 - ERROR - Error in batch 314: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,459 - ERROR - Error in batch 315: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,470 - ERROR - Error in batch 316: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,480 - ERROR - Error in batch 317: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,491 - ERROR - Error in batch 318: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,502 - ERROR - Error in batch 319: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,516 - ERROR - Error in batch 320: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,529 - ERROR - Error in batch 321: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,542 - ERROR - Error in batch 322: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,555 - ERROR - Error in batch 323: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,567 - ERROR - Error in batch 324: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,580 - ERROR - Error in batch 325: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,593 - ERROR - Error in batch 326: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,605 - ERROR - Error in batch 327: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,617 - ERROR - Error in batch 328: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,630 - ERROR - Error in batch 329: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,643 - ERROR - Error in batch 330: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,655 - ERROR - Error in batch 331: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,667 - ERROR - Error in batch 332: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,680 - ERROR - Error in batch 333: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,694 - ERROR - Error in batch 334: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,707 - ERROR - Error in batch 335: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,720 - ERROR - Error in batch 336: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,733 - ERROR - Error in batch 337: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,746 - ERROR - Error in batch 338: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,759 - ERROR - Error in batch 339: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,773 - ERROR - Error in batch 340: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,783 - ERROR - Error in batch 341: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,794 - ERROR - Error in batch 342: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,807 - ERROR - Error in batch 343: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,818 - ERROR - Error in batch 344: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,831 - ERROR - Error in batch 345: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,844 - ERROR - Error in batch 346: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,857 - ERROR - Error in batch 347: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,870 - ERROR - Error in batch 348: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,883 - ERROR - Error in batch 349: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,893 - ERROR - Error in batch 350: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,904 - ERROR - Error in batch 351: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,916 - ERROR - Error in batch 352: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,929 - ERROR - Error in batch 353: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,942 - ERROR - Error in batch 354: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,954 - ERROR - Error in batch 355: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,965 - ERROR - Error in batch 356: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,975 - ERROR - Error in batch 357: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,986 - ERROR - Error in batch 358: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:48,997 - ERROR - Error in batch 359: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,008 - ERROR - Error in batch 360: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,020 - ERROR - Error in batch 361: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,033 - ERROR - Error in batch 362: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,046 - ERROR - Error in batch 363: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,059 - ERROR - Error in batch 364: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,073 - ERROR - Error in batch 365: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,086 - ERROR - Error in batch 366: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,098 - ERROR - Error in batch 367: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,111 - ERROR - Error in batch 368: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,124 - ERROR - Error in batch 369: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,137 - ERROR - Error in batch 370: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,149 - ERROR - Error in batch 371: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,162 - ERROR - Error in batch 372: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,174 - ERROR - Error in batch 373: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,186 - ERROR - Error in batch 374: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,199 - ERROR - Error in batch 375: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,212 - ERROR - Error in batch 376: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,224 - ERROR - Error in batch 377: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,237 - ERROR - Error in batch 378: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,250 - ERROR - Error in batch 379: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,263 - ERROR - Error in batch 380: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,276 - ERROR - Error in batch 381: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,289 - ERROR - Error in batch 382: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,302 - ERROR - Error in batch 383: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,315 - ERROR - Error in batch 384: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,327 - ERROR - Error in batch 385: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,340 - ERROR - Error in batch 386: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,355 - ERROR - Error in batch 387: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,431 - ERROR - Error in batch 388: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,443 - ERROR - Error in batch 389: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,456 - ERROR - Error in batch 390: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,470 - ERROR - Error in batch 391: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,483 - ERROR - Error in batch 392: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,496 - ERROR - Error in batch 393: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,508 - ERROR - Error in batch 394: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,521 - ERROR - Error in batch 395: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,534 - ERROR - Error in batch 396: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,547 - ERROR - Error in batch 397: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,560 - ERROR - Error in batch 398: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,573 - ERROR - Error in batch 399: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,586 - ERROR - Error in batch 400: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,599 - ERROR - Error in batch 401: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,611 - ERROR - Error in batch 402: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,624 - ERROR - Error in batch 403: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,636 - ERROR - Error in batch 404: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,649 - ERROR - Error in batch 405: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,663 - ERROR - Error in batch 406: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,675 - ERROR - Error in batch 407: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,688 - ERROR - Error in batch 408: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,701 - ERROR - Error in batch 409: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,714 - ERROR - Error in batch 410: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,727 - ERROR - Error in batch 411: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,739 - ERROR - Error in batch 412: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,752 - ERROR - Error in batch 413: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,764 - ERROR - Error in batch 414: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,777 - ERROR - Error in batch 415: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,790 - ERROR - Error in batch 416: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,803 - ERROR - Error in batch 417: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,816 - ERROR - Error in batch 418: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,828 - ERROR - Error in batch 419: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,841 - ERROR - Error in batch 420: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,853 - ERROR - Error in batch 421: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,866 - ERROR - Error in batch 422: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,879 - ERROR - Error in batch 423: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,892 - ERROR - Error in batch 424: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,905 - ERROR - Error in batch 425: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,917 - ERROR - Error in batch 426: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,930 - ERROR - Error in batch 427: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,943 - ERROR - Error in batch 428: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,955 - ERROR - Error in batch 429: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,968 - ERROR - Error in batch 430: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,980 - ERROR - Error in batch 431: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:49,993 - ERROR - Error in batch 432: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,006 - ERROR - Error in batch 433: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,019 - ERROR - Error in batch 434: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,032 - ERROR - Error in batch 435: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,046 - ERROR - Error in batch 436: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,059 - ERROR - Error in batch 437: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,071 - ERROR - Error in batch 438: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,084 - ERROR - Error in batch 439: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,096 - ERROR - Error in batch 440: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,109 - ERROR - Error in batch 441: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,121 - ERROR - Error in batch 442: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,134 - ERROR - Error in batch 443: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,146 - ERROR - Error in batch 444: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,159 - ERROR - Error in batch 445: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,172 - ERROR - Error in batch 446: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,186 - ERROR - Error in batch 447: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,199 - ERROR - Error in batch 448: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,213 - ERROR - Error in batch 449: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,228 - ERROR - Error in batch 450: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,241 - ERROR - Error in batch 451: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,254 - ERROR - Error in batch 452: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,265 - ERROR - Error in batch 453: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,276 - ERROR - Error in batch 454: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,287 - ERROR - Error in batch 455: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,299 - ERROR - Error in batch 456: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,312 - ERROR - Error in batch 457: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,327 - ERROR - Error in batch 458: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,339 - ERROR - Error in batch 459: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,352 - ERROR - Error in batch 460: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,365 - ERROR - Error in batch 461: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,375 - ERROR - Error in batch 462: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,389 - ERROR - Error in batch 463: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,402 - ERROR - Error in batch 464: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,412 - ERROR - Error in batch 465: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,424 - ERROR - Error in batch 466: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,437 - ERROR - Error in batch 467: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,453 - ERROR - Error in batch 468: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,527 - ERROR - Error in batch 469: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,539 - ERROR - Error in batch 470: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,552 - ERROR - Error in batch 471: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,565 - ERROR - Error in batch 472: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,577 - ERROR - Error in batch 473: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,590 - ERROR - Error in batch 474: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,603 - ERROR - Error in batch 475: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,616 - ERROR - Error in batch 476: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,629 - ERROR - Error in batch 477: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,642 - ERROR - Error in batch 478: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,653 - ERROR - Error in batch 479: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,666 - ERROR - Error in batch 480: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,679 - ERROR - Error in batch 481: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,689 - ERROR - Error in batch 482: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,701 - ERROR - Error in batch 483: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,714 - ERROR - Error in batch 484: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,727 - ERROR - Error in batch 485: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,740 - ERROR - Error in batch 486: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,753 - ERROR - Error in batch 487: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,764 - ERROR - Error in batch 488: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,778 - ERROR - Error in batch 489: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,791 - ERROR - Error in batch 490: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,802 - ERROR - Error in batch 491: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,814 - ERROR - Error in batch 492: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,827 - ERROR - Error in batch 493: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,840 - ERROR - Error in batch 494: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,853 - ERROR - Error in batch 495: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,866 - ERROR - Error in batch 496: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,876 - ERROR - Error in batch 497: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,890 - ERROR - Error in batch 498: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,901 - ERROR - Error in batch 499: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,912 - ERROR - Error in batch 500: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,924 - ERROR - Error in batch 501: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,935 - ERROR - Error in batch 502: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,948 - ERROR - Error in batch 503: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,960 - ERROR - Error in batch 504: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,972 - ERROR - Error in batch 505: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,984 - ERROR - Error in batch 506: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:50,997 - ERROR - Error in batch 507: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:49:51,010 - ERROR - Error in batch 508: CUDA out of memory. Tried to allocate 54.64 GiB. GPU 0 has a total capacity of 23.53 GiB of which 8.81 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.18 GiB is allocated by PyTorch, and 65.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:55:57,558 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:55:57,627 - INFO - Using device: cuda
2025-12-08 13:55:57,645 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:55:57,645 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:55:59,641 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 13:55:59,743 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 13:55:59,743 - INFO - Creating ELMo BiLM model...
2025-12-08 13:56:29,007 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:56:29,009 - INFO - Creating data loader...
2025-12-08 13:56:29,315 - INFO - Data loader created successfully
2025-12-08 13:56:29,315 - INFO - Starting training...
2025-12-08 13:56:29,315 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:56:29,315 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_135629
2025-12-08 13:56:29,607 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,792 - ERROR - Error in batch 0: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,793 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,804 - ERROR - Error in batch 1: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,804 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,815 - ERROR - Error in batch 2: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,815 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,826 - ERROR - Error in batch 3: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,826 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,837 - ERROR - Error in batch 4: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,837 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,849 - ERROR - Error in batch 5: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,849 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,860 - ERROR - Error in batch 6: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,860 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,871 - ERROR - Error in batch 7: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,871 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,883 - ERROR - Error in batch 8: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,883 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,894 - ERROR - Error in batch 9: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,894 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,906 - ERROR - Error in batch 10: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,906 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,917 - ERROR - Error in batch 11: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,917 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,928 - ERROR - Error in batch 12: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,928 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,939 - ERROR - Error in batch 13: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,939 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,950 - ERROR - Error in batch 14: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,950 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,961 - ERROR - Error in batch 15: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,961 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,971 - ERROR - Error in batch 16: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,972 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,981 - ERROR - Error in batch 17: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,982 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:29,991 - ERROR - Error in batch 18: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:29,992 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,001 - ERROR - Error in batch 19: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,002 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,011 - ERROR - Error in batch 20: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,012 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,021 - ERROR - Error in batch 21: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,022 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,032 - ERROR - Error in batch 22: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,032 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,041 - ERROR - Error in batch 23: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,042 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,053 - ERROR - Error in batch 24: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,053 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,064 - ERROR - Error in batch 25: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,064 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,073 - ERROR - Error in batch 26: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,074 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,085 - ERROR - Error in batch 27: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,085 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,095 - ERROR - Error in batch 28: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,096 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,106 - ERROR - Error in batch 29: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,106 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,115 - ERROR - Error in batch 30: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,116 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,125 - ERROR - Error in batch 31: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,126 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,135 - ERROR - Error in batch 32: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,136 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,146 - ERROR - Error in batch 33: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,146 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,155 - ERROR - Error in batch 34: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,156 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,166 - ERROR - Error in batch 35: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,166 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,176 - ERROR - Error in batch 36: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,176 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,185 - ERROR - Error in batch 37: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,186 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,195 - ERROR - Error in batch 38: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,196 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,206 - ERROR - Error in batch 39: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,206 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,217 - ERROR - Error in batch 40: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,217 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,227 - ERROR - Error in batch 41: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,227 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,238 - ERROR - Error in batch 42: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,238 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,247 - ERROR - Error in batch 43: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,248 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,258 - ERROR - Error in batch 44: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,259 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,268 - ERROR - Error in batch 45: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,269 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,278 - ERROR - Error in batch 46: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,279 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,288 - ERROR - Error in batch 47: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,289 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,299 - ERROR - Error in batch 48: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,300 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,310 - ERROR - Error in batch 49: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,310 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,319 - ERROR - Error in batch 50: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,320 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,329 - ERROR - Error in batch 51: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,330 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,339 - ERROR - Error in batch 52: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,340 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,349 - ERROR - Error in batch 53: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,350 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,360 - ERROR - Error in batch 54: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,361 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,372 - ERROR - Error in batch 55: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,373 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,383 - ERROR - Error in batch 56: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,383 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,393 - ERROR - Error in batch 57: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,393 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,404 - ERROR - Error in batch 58: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,405 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,471 - ERROR - Error in batch 59: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,471 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,480 - ERROR - Error in batch 60: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,481 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,490 - ERROR - Error in batch 61: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,491 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,500 - ERROR - Error in batch 62: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,501 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,511 - ERROR - Error in batch 63: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,512 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,522 - ERROR - Error in batch 64: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,523 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,532 - ERROR - Error in batch 65: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,533 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,542 - ERROR - Error in batch 66: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,543 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,552 - ERROR - Error in batch 67: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,553 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,564 - ERROR - Error in batch 68: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,564 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,574 - ERROR - Error in batch 69: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,575 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,585 - ERROR - Error in batch 70: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,585 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,594 - ERROR - Error in batch 71: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,595 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,606 - ERROR - Error in batch 72: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,606 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,615 - ERROR - Error in batch 73: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,616 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,625 - ERROR - Error in batch 74: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,626 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,636 - ERROR - Error in batch 75: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,636 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,645 - ERROR - Error in batch 76: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,646 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,655 - ERROR - Error in batch 77: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,656 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,666 - ERROR - Error in batch 78: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,666 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,677 - ERROR - Error in batch 79: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,677 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,686 - ERROR - Error in batch 80: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,687 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,697 - ERROR - Error in batch 81: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,697 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,707 - ERROR - Error in batch 82: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,708 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,717 - ERROR - Error in batch 83: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,718 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,727 - ERROR - Error in batch 84: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,728 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,738 - ERROR - Error in batch 85: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,739 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,748 - ERROR - Error in batch 86: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,749 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,760 - ERROR - Error in batch 87: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,760 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,769 - ERROR - Error in batch 88: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,770 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,781 - ERROR - Error in batch 89: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,781 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,790 - ERROR - Error in batch 90: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,791 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,800 - ERROR - Error in batch 91: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,801 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,810 - ERROR - Error in batch 92: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,811 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,820 - ERROR - Error in batch 93: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,821 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,830 - ERROR - Error in batch 94: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,831 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,841 - ERROR - Error in batch 95: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,841 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,851 - ERROR - Error in batch 96: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,852 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,861 - ERROR - Error in batch 97: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,862 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,873 - ERROR - Error in batch 98: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,873 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,882 - ERROR - Error in batch 99: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,883 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,893 - ERROR - Error in batch 100: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,893 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,904 - ERROR - Error in batch 101: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,904 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,914 - ERROR - Error in batch 102: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,915 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,924 - ERROR - Error in batch 103: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,925 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,935 - ERROR - Error in batch 104: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,936 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,946 - ERROR - Error in batch 105: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,946 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,955 - ERROR - Error in batch 106: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,956 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,965 - ERROR - Error in batch 107: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,966 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,976 - ERROR - Error in batch 108: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,976 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,985 - ERROR - Error in batch 109: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,986 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:30,995 - ERROR - Error in batch 110: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:30,996 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,006 - ERROR - Error in batch 111: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,007 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,017 - ERROR - Error in batch 112: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,017 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,027 - ERROR - Error in batch 113: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,028 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,037 - ERROR - Error in batch 114: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,038 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,048 - ERROR - Error in batch 115: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,049 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,058 - ERROR - Error in batch 116: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,059 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,069 - ERROR - Error in batch 117: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,070 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,079 - ERROR - Error in batch 118: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,080 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,089 - ERROR - Error in batch 119: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,090 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,099 - ERROR - Error in batch 120: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,100 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,111 - ERROR - Error in batch 121: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,111 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,120 - ERROR - Error in batch 122: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,121 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,130 - ERROR - Error in batch 123: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,131 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,140 - ERROR - Error in batch 124: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,141 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,150 - ERROR - Error in batch 125: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,151 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,160 - ERROR - Error in batch 126: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,161 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,170 - ERROR - Error in batch 127: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,171 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,180 - ERROR - Error in batch 128: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,181 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,190 - ERROR - Error in batch 129: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,191 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,200 - ERROR - Error in batch 130: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,201 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,211 - ERROR - Error in batch 131: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,212 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,221 - ERROR - Error in batch 132: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,222 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,232 - ERROR - Error in batch 133: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,233 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,243 - ERROR - Error in batch 134: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,243 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,252 - ERROR - Error in batch 135: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,253 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,263 - ERROR - Error in batch 136: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,263 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,273 - ERROR - Error in batch 137: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,274 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,284 - ERROR - Error in batch 138: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,284 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,294 - ERROR - Error in batch 139: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,294 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,303 - ERROR - Error in batch 140: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,304 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,314 - ERROR - Error in batch 141: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,314 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,324 - ERROR - Error in batch 142: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,325 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,337 - ERROR - Error in batch 143: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,337 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,346 - ERROR - Error in batch 144: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,347 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,356 - ERROR - Error in batch 145: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,357 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,367 - ERROR - Error in batch 146: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,367 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,379 - ERROR - Error in batch 147: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,379 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,388 - ERROR - Error in batch 148: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,389 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,400 - ERROR - Error in batch 149: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,400 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,410 - ERROR - Error in batch 150: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,411 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,421 - ERROR - Error in batch 151: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,421 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,430 - ERROR - Error in batch 152: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,431 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,442 - ERROR - Error in batch 153: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,442 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,451 - ERROR - Error in batch 154: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,452 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,461 - ERROR - Error in batch 155: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,462 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,472 - ERROR - Error in batch 156: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,472 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,483 - ERROR - Error in batch 157: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,483 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,497 - ERROR - Error in batch 158: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,498 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,568 - ERROR - Error in batch 159: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,568 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,577 - ERROR - Error in batch 160: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,578 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,588 - ERROR - Error in batch 161: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,588 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,598 - ERROR - Error in batch 162: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,598 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,609 - ERROR - Error in batch 163: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,609 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,619 - ERROR - Error in batch 164: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,619 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,629 - ERROR - Error in batch 165: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,630 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,639 - ERROR - Error in batch 166: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,640 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,649 - ERROR - Error in batch 167: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,650 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,659 - ERROR - Error in batch 168: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,660 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,671 - ERROR - Error in batch 169: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,671 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,680 - ERROR - Error in batch 170: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,681 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,690 - ERROR - Error in batch 171: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,691 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,700 - ERROR - Error in batch 172: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,701 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,711 - ERROR - Error in batch 173: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,711 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,721 - ERROR - Error in batch 174: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,721 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,732 - ERROR - Error in batch 175: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,732 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,741 - ERROR - Error in batch 176: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,742 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,752 - ERROR - Error in batch 177: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,752 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,761 - ERROR - Error in batch 178: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,762 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,773 - ERROR - Error in batch 179: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,773 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,782 - ERROR - Error in batch 180: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,783 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,794 - ERROR - Error in batch 181: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,794 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,804 - ERROR - Error in batch 182: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,805 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,814 - ERROR - Error in batch 183: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,815 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,825 - ERROR - Error in batch 184: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,825 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,834 - ERROR - Error in batch 185: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,835 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,845 - ERROR - Error in batch 186: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,845 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,857 - ERROR - Error in batch 187: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,857 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,866 - ERROR - Error in batch 188: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,867 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,876 - ERROR - Error in batch 189: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,877 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,886 - ERROR - Error in batch 190: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,887 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,898 - ERROR - Error in batch 191: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,898 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,908 - ERROR - Error in batch 192: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,908 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,917 - ERROR - Error in batch 193: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,918 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,927 - ERROR - Error in batch 194: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,928 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,938 - ERROR - Error in batch 195: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,939 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,949 - ERROR - Error in batch 196: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,949 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,961 - ERROR - Error in batch 197: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,961 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,971 - ERROR - Error in batch 198: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,972 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,981 - ERROR - Error in batch 199: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,982 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:31,991 - ERROR - Error in batch 200: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:31,992 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,001 - ERROR - Error in batch 201: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,002 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,011 - ERROR - Error in batch 202: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,012 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,023 - ERROR - Error in batch 203: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,023 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,032 - ERROR - Error in batch 204: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,033 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,044 - ERROR - Error in batch 205: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,044 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,053 - ERROR - Error in batch 206: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,054 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,063 - ERROR - Error in batch 207: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,064 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,074 - ERROR - Error in batch 208: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,074 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,083 - ERROR - Error in batch 209: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,084 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,093 - ERROR - Error in batch 210: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,094 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,106 - ERROR - Error in batch 211: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,106 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,118 - ERROR - Error in batch 212: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,118 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,129 - ERROR - Error in batch 213: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,129 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,140 - ERROR - Error in batch 214: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,140 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,149 - ERROR - Error in batch 215: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,150 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,160 - ERROR - Error in batch 216: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,160 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,170 - ERROR - Error in batch 217: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,170 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,181 - ERROR - Error in batch 218: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,181 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,192 - ERROR - Error in batch 219: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,192 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,201 - ERROR - Error in batch 220: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,202 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,212 - ERROR - Error in batch 221: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,213 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,222 - ERROR - Error in batch 222: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,223 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,234 - ERROR - Error in batch 223: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,234 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,243 - ERROR - Error in batch 224: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,244 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,253 - ERROR - Error in batch 225: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,254 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,264 - ERROR - Error in batch 226: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,264 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,276 - ERROR - Error in batch 227: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,276 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,285 - ERROR - Error in batch 228: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,286 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,297 - ERROR - Error in batch 229: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,298 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,307 - ERROR - Error in batch 230: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,308 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,317 - ERROR - Error in batch 231: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,318 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,327 - ERROR - Error in batch 232: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,328 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,337 - ERROR - Error in batch 233: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,338 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,348 - ERROR - Error in batch 234: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,348 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,358 - ERROR - Error in batch 235: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,359 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,368 - ERROR - Error in batch 236: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,369 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,379 - ERROR - Error in batch 237: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,380 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,390 - ERROR - Error in batch 238: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,390 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,400 - ERROR - Error in batch 239: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,400 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,409 - ERROR - Error in batch 240: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,410 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,419 - ERROR - Error in batch 241: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,420 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,430 - ERROR - Error in batch 242: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,430 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,440 - ERROR - Error in batch 243: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,441 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,450 - ERROR - Error in batch 244: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,451 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,461 - ERROR - Error in batch 245: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,462 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,471 - ERROR - Error in batch 246: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,472 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,483 - ERROR - Error in batch 247: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,483 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,492 - ERROR - Error in batch 248: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,493 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,502 - ERROR - Error in batch 249: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,503 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,512 - ERROR - Error in batch 250: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,513 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,524 - ERROR - Error in batch 251: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,524 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,533 - ERROR - Error in batch 252: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,534 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,545 - ERROR - Error in batch 253: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,545 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,555 - ERROR - Error in batch 254: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,556 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,565 - ERROR - Error in batch 255: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,566 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,576 - ERROR - Error in batch 256: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,576 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,586 - ERROR - Error in batch 257: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,586 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,661 - ERROR - Error in batch 258: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,662 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,672 - ERROR - Error in batch 259: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,672 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,683 - ERROR - Error in batch 260: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,683 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,693 - ERROR - Error in batch 261: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,694 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,703 - ERROR - Error in batch 262: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,704 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,714 - ERROR - Error in batch 263: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,714 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,723 - ERROR - Error in batch 264: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,724 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,733 - ERROR - Error in batch 265: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,734 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,743 - ERROR - Error in batch 266: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,744 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,754 - ERROR - Error in batch 267: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,755 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,766 - ERROR - Error in batch 268: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,767 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,777 - ERROR - Error in batch 269: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,777 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,786 - ERROR - Error in batch 270: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,787 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,796 - ERROR - Error in batch 271: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,797 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,806 - ERROR - Error in batch 272: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,807 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,817 - ERROR - Error in batch 273: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,817 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,828 - ERROR - Error in batch 274: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,829 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,838 - ERROR - Error in batch 275: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,839 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,850 - ERROR - Error in batch 276: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,850 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,862 - ERROR - Error in batch 277: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,862 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,872 - ERROR - Error in batch 278: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,872 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,882 - ERROR - Error in batch 279: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,882 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,891 - ERROR - Error in batch 280: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,892 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,902 - ERROR - Error in batch 281: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,902 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,912 - ERROR - Error in batch 282: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,912 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,922 - ERROR - Error in batch 283: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,923 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,934 - ERROR - Error in batch 284: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,934 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,944 - ERROR - Error in batch 285: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,944 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,953 - ERROR - Error in batch 286: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,954 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,964 - ERROR - Error in batch 287: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,964 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,973 - ERROR - Error in batch 288: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,974 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,986 - ERROR - Error in batch 289: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,986 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:32,995 - ERROR - Error in batch 290: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:32,996 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,005 - ERROR - Error in batch 291: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,006 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,015 - ERROR - Error in batch 292: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,016 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,027 - ERROR - Error in batch 293: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,028 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,038 - ERROR - Error in batch 294: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,039 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,048 - ERROR - Error in batch 295: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,049 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,060 - ERROR - Error in batch 296: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,060 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,069 - ERROR - Error in batch 297: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,070 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,079 - ERROR - Error in batch 298: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,080 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,090 - ERROR - Error in batch 299: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,091 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,101 - ERROR - Error in batch 300: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,102 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,111 - ERROR - Error in batch 301: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,112 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,122 - ERROR - Error in batch 302: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,122 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,131 - ERROR - Error in batch 303: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,132 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,142 - ERROR - Error in batch 304: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,142 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,151 - ERROR - Error in batch 305: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,152 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,161 - ERROR - Error in batch 306: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,162 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,172 - ERROR - Error in batch 307: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,172 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,183 - ERROR - Error in batch 308: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,183 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,193 - ERROR - Error in batch 309: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,194 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,204 - ERROR - Error in batch 310: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,205 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,216 - ERROR - Error in batch 311: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,216 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,227 - ERROR - Error in batch 312: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,227 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,236 - ERROR - Error in batch 313: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,237 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,246 - ERROR - Error in batch 314: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,247 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,259 - ERROR - Error in batch 315: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,259 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,269 - ERROR - Error in batch 316: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,269 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,278 - ERROR - Error in batch 317: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,279 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,288 - ERROR - Error in batch 318: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,289 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,298 - ERROR - Error in batch 319: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,299 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,309 - ERROR - Error in batch 320: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,310 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,319 - ERROR - Error in batch 321: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,320 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,330 - ERROR - Error in batch 322: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,330 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,339 - ERROR - Error in batch 323: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,340 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,349 - ERROR - Error in batch 324: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,350 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,360 - ERROR - Error in batch 325: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,361 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,370 - ERROR - Error in batch 326: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,371 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,382 - ERROR - Error in batch 327: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,382 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,391 - ERROR - Error in batch 328: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,392 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,403 - ERROR - Error in batch 329: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,403 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,412 - ERROR - Error in batch 330: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,413 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,423 - ERROR - Error in batch 331: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,424 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,433 - ERROR - Error in batch 332: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,434 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,443 - ERROR - Error in batch 333: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,444 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,453 - ERROR - Error in batch 334: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,454 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,463 - ERROR - Error in batch 335: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,464 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,473 - ERROR - Error in batch 336: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,474 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,483 - ERROR - Error in batch 337: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,484 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,493 - ERROR - Error in batch 338: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,494 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,505 - ERROR - Error in batch 339: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,505 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,514 - ERROR - Error in batch 340: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,515 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,526 - ERROR - Error in batch 341: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,526 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,537 - ERROR - Error in batch 342: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,537 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,546 - ERROR - Error in batch 343: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,547 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,556 - ERROR - Error in batch 344: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,557 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,568 - ERROR - Error in batch 345: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,568 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,577 - ERROR - Error in batch 346: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,578 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,587 - ERROR - Error in batch 347: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,588 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,598 - ERROR - Error in batch 348: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,598 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,607 - ERROR - Error in batch 349: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,608 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,619 - ERROR - Error in batch 350: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,619 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,629 - ERROR - Error in batch 351: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,629 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,639 - ERROR - Error in batch 352: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,640 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,650 - ERROR - Error in batch 353: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,650 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,661 - ERROR - Error in batch 354: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,661 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,672 - ERROR - Error in batch 355: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,672 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,681 - ERROR - Error in batch 356: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,682 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,756 - ERROR - Error in batch 357: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,757 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,768 - ERROR - Error in batch 358: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,768 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,777 - ERROR - Error in batch 359: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,778 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,787 - ERROR - Error in batch 360: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,788 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,799 - ERROR - Error in batch 361: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,799 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,808 - ERROR - Error in batch 362: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,809 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,818 - ERROR - Error in batch 363: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,819 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,828 - ERROR - Error in batch 364: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,829 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,838 - ERROR - Error in batch 365: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,839 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,850 - ERROR - Error in batch 366: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,850 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,859 - ERROR - Error in batch 367: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,860 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,871 - ERROR - Error in batch 368: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,871 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,880 - ERROR - Error in batch 369: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,881 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,890 - ERROR - Error in batch 370: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,891 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,900 - ERROR - Error in batch 371: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,901 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,911 - ERROR - Error in batch 372: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,911 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,921 - ERROR - Error in batch 373: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,922 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,933 - ERROR - Error in batch 374: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,933 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,942 - ERROR - Error in batch 375: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,943 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,952 - ERROR - Error in batch 376: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,953 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,964 - ERROR - Error in batch 377: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,964 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,975 - ERROR - Error in batch 378: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,975 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,985 - ERROR - Error in batch 379: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,985 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:33,994 - ERROR - Error in batch 380: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:33,995 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,004 - ERROR - Error in batch 381: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,005 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,014 - ERROR - Error in batch 382: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,015 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,024 - ERROR - Error in batch 383: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,025 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,034 - ERROR - Error in batch 384: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,035 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,044 - ERROR - Error in batch 385: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,045 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,055 - ERROR - Error in batch 386: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,055 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,066 - ERROR - Error in batch 387: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,066 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,075 - ERROR - Error in batch 388: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,076 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,086 - ERROR - Error in batch 389: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,086 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,095 - ERROR - Error in batch 390: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,096 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,105 - ERROR - Error in batch 391: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,106 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,117 - ERROR - Error in batch 392: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,117 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,128 - ERROR - Error in batch 393: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,128 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,139 - ERROR - Error in batch 394: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,140 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,149 - ERROR - Error in batch 395: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,150 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,159 - ERROR - Error in batch 396: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,160 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,170 - ERROR - Error in batch 397: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,170 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,179 - ERROR - Error in batch 398: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,180 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,190 - ERROR - Error in batch 399: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,190 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,199 - ERROR - Error in batch 400: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,200 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,210 - ERROR - Error in batch 401: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,210 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,219 - ERROR - Error in batch 402: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,220 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,230 - ERROR - Error in batch 403: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,230 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,239 - ERROR - Error in batch 404: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,240 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,249 - ERROR - Error in batch 405: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,250 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,261 - ERROR - Error in batch 406: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,261 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,270 - ERROR - Error in batch 407: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,271 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,280 - ERROR - Error in batch 408: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,281 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,290 - ERROR - Error in batch 409: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,291 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,300 - ERROR - Error in batch 410: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,301 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,311 - ERROR - Error in batch 411: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,311 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,320 - ERROR - Error in batch 412: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,321 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,331 - ERROR - Error in batch 413: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,331 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,340 - ERROR - Error in batch 414: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,341 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,351 - ERROR - Error in batch 415: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,352 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,361 - ERROR - Error in batch 416: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,362 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,371 - ERROR - Error in batch 417: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,372 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,382 - ERROR - Error in batch 418: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,382 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,392 - ERROR - Error in batch 419: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,392 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,401 - ERROR - Error in batch 420: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,402 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,411 - ERROR - Error in batch 421: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,412 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,421 - ERROR - Error in batch 422: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,422 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,433 - ERROR - Error in batch 423: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,433 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,442 - ERROR - Error in batch 424: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,443 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,452 - ERROR - Error in batch 425: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,453 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,464 - ERROR - Error in batch 426: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,464 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,474 - ERROR - Error in batch 427: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,474 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,484 - ERROR - Error in batch 428: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,485 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,496 - ERROR - Error in batch 429: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,496 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,505 - ERROR - Error in batch 430: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,506 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,515 - ERROR - Error in batch 431: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,516 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,525 - ERROR - Error in batch 432: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,526 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,535 - ERROR - Error in batch 433: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,536 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,546 - ERROR - Error in batch 434: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,546 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,557 - ERROR - Error in batch 435: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,557 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,567 - ERROR - Error in batch 436: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,568 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,577 - ERROR - Error in batch 437: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,578 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,588 - ERROR - Error in batch 438: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,588 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,597 - ERROR - Error in batch 439: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,598 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,608 - ERROR - Error in batch 440: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,608 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,617 - ERROR - Error in batch 441: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,618 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,628 - ERROR - Error in batch 442: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,628 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,637 - ERROR - Error in batch 443: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,638 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,648 - ERROR - Error in batch 444: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,648 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,659 - ERROR - Error in batch 445: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,659 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,669 - ERROR - Error in batch 446: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,669 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,680 - ERROR - Error in batch 447: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,680 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,692 - ERROR - Error in batch 448: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,692 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,703 - ERROR - Error in batch 449: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,703 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,714 - ERROR - Error in batch 450: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,715 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,725 - ERROR - Error in batch 451: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,725 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,736 - ERROR - Error in batch 452: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,736 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,747 - ERROR - Error in batch 453: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,747 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,758 - ERROR - Error in batch 454: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,758 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,769 - ERROR - Error in batch 455: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,769 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,780 - ERROR - Error in batch 456: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,780 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,854 - ERROR - Error in batch 457: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,855 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,865 - ERROR - Error in batch 458: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,865 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,876 - ERROR - Error in batch 459: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,877 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,887 - ERROR - Error in batch 460: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,887 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,898 - ERROR - Error in batch 461: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,898 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,908 - ERROR - Error in batch 462: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,908 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,919 - ERROR - Error in batch 463: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,919 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,930 - ERROR - Error in batch 464: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,930 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,941 - ERROR - Error in batch 465: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,941 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,952 - ERROR - Error in batch 466: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,953 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,963 - ERROR - Error in batch 467: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,963 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,974 - ERROR - Error in batch 468: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,974 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,985 - ERROR - Error in batch 469: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,985 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:34,996 - ERROR - Error in batch 470: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:34,997 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,007 - ERROR - Error in batch 471: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,007 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,018 - ERROR - Error in batch 472: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,018 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,029 - ERROR - Error in batch 473: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,029 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,040 - ERROR - Error in batch 474: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,040 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,051 - ERROR - Error in batch 475: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,051 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,062 - ERROR - Error in batch 476: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,062 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,073 - ERROR - Error in batch 477: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,073 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,084 - ERROR - Error in batch 478: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,084 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,095 - ERROR - Error in batch 479: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,096 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,107 - ERROR - Error in batch 480: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,107 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,118 - ERROR - Error in batch 481: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,118 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,129 - ERROR - Error in batch 482: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,129 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,140 - ERROR - Error in batch 483: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,140 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,152 - ERROR - Error in batch 484: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,152 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,164 - ERROR - Error in batch 485: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,164 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,174 - ERROR - Error in batch 486: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,174 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,184 - ERROR - Error in batch 487: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,185 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,194 - ERROR - Error in batch 488: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,195 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,204 - ERROR - Error in batch 489: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,205 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,216 - ERROR - Error in batch 490: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,216 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,225 - ERROR - Error in batch 491: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,226 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,236 - ERROR - Error in batch 492: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,236 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,245 - ERROR - Error in batch 493: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,246 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,255 - ERROR - Error in batch 494: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,256 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,265 - ERROR - Error in batch 495: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,266 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,276 - ERROR - Error in batch 496: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,276 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,285 - ERROR - Error in batch 497: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,286 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,296 - ERROR - Error in batch 498: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,296 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,306 - ERROR - Error in batch 499: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,307 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,317 - ERROR - Error in batch 500: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,317 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,326 - ERROR - Error in batch 501: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,327 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,336 - ERROR - Error in batch 502: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,337 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,348 - ERROR - Error in batch 503: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,348 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,357 - ERROR - Error in batch 504: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,358 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,367 - ERROR - Error in batch 505: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,368 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,378 - ERROR - Error in batch 506: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,378 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,387 - ERROR - Error in batch 507: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,388 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,397 - ERROR - Error in batch 508: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,398 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,408 - ERROR - Error in batch 509: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,409 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,419 - ERROR - Error in batch 510: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,420 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,429 - ERROR - Error in batch 511: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,430 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,440 - ERROR - Error in batch 512: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,440 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,450 - ERROR - Error in batch 513: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,450 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,461 - ERROR - Error in batch 514: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,461 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,472 - ERROR - Error in batch 515: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,473 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,483 - ERROR - Error in batch 516: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,483 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,494 - ERROR - Error in batch 517: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,494 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,505 - ERROR - Error in batch 518: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,505 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,516 - ERROR - Error in batch 519: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,516 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,527 - ERROR - Error in batch 520: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,527 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,538 - ERROR - Error in batch 521: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,538 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,549 - ERROR - Error in batch 522: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,549 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,560 - ERROR - Error in batch 523: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,560 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,571 - ERROR - Error in batch 524: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,572 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,582 - ERROR - Error in batch 525: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,582 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,593 - ERROR - Error in batch 526: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,593 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,604 - ERROR - Error in batch 527: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,605 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,616 - ERROR - Error in batch 528: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,617 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,627 - ERROR - Error in batch 529: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,627 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,638 - ERROR - Error in batch 530: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,639 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,649 - ERROR - Error in batch 531: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,649 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,660 - ERROR - Error in batch 532: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,661 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,671 - ERROR - Error in batch 533: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,671 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,682 - ERROR - Error in batch 534: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,682 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,693 - ERROR - Error in batch 535: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,693 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,704 - ERROR - Error in batch 536: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,704 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,715 - ERROR - Error in batch 537: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,715 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,726 - ERROR - Error in batch 538: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,726 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,737 - ERROR - Error in batch 539: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,737 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,748 - ERROR - Error in batch 540: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,748 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,759 - ERROR - Error in batch 541: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,759 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,770 - ERROR - Error in batch 542: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,770 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,781 - ERROR - Error in batch 543: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,781 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,792 - ERROR - Error in batch 544: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,792 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,803 - ERROR - Error in batch 545: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,803 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,814 - ERROR - Error in batch 546: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,815 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,825 - ERROR - Error in batch 547: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,825 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,836 - ERROR - Error in batch 548: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,836 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,847 - ERROR - Error in batch 549: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,847 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,858 - ERROR - Error in batch 550: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,859 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,869 - ERROR - Error in batch 551: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,870 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,882 - ERROR - Error in batch 552: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,882 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,953 - ERROR - Error in batch 553: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,953 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,964 - ERROR - Error in batch 554: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,965 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,975 - ERROR - Error in batch 555: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,975 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,986 - ERROR - Error in batch 556: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,986 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:35,997 - ERROR - Error in batch 557: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:35,998 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,008 - ERROR - Error in batch 558: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,008 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,020 - ERROR - Error in batch 559: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,021 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,031 - ERROR - Error in batch 560: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,031 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,042 - ERROR - Error in batch 561: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,042 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,053 - ERROR - Error in batch 562: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,053 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,064 - ERROR - Error in batch 563: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,064 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,075 - ERROR - Error in batch 564: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,075 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,086 - ERROR - Error in batch 565: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,086 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,097 - ERROR - Error in batch 566: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,097 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,108 - ERROR - Error in batch 567: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,108 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,119 - ERROR - Error in batch 568: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,119 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,130 - ERROR - Error in batch 569: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,131 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,141 - ERROR - Error in batch 570: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,141 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,152 - ERROR - Error in batch 571: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,152 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,163 - ERROR - Error in batch 572: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,164 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,174 - ERROR - Error in batch 573: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,174 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,185 - ERROR - Error in batch 574: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,185 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,196 - ERROR - Error in batch 575: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,196 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,207 - ERROR - Error in batch 576: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,207 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,218 - ERROR - Error in batch 577: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,219 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,229 - ERROR - Error in batch 578: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,229 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,240 - ERROR - Error in batch 579: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,241 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,251 - ERROR - Error in batch 580: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,251 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,262 - ERROR - Error in batch 581: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,262 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,273 - ERROR - Error in batch 582: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,273 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,284 - ERROR - Error in batch 583: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,284 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,295 - ERROR - Error in batch 584: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,295 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,306 - ERROR - Error in batch 585: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,306 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,318 - ERROR - Error in batch 586: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,318 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,329 - ERROR - Error in batch 587: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,329 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,340 - ERROR - Error in batch 588: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,341 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,351 - ERROR - Error in batch 589: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,351 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,362 - ERROR - Error in batch 590: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,362 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,373 - ERROR - Error in batch 591: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,374 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,384 - ERROR - Error in batch 592: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,384 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,395 - ERROR - Error in batch 593: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,396 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,406 - ERROR - Error in batch 594: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,406 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,416 - ERROR - Error in batch 595: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,416 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,427 - ERROR - Error in batch 596: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,428 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,438 - ERROR - Error in batch 597: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,438 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,448 - ERROR - Error in batch 598: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,448 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,459 - ERROR - Error in batch 599: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,459 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,470 - ERROR - Error in batch 600: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,470 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,481 - ERROR - Error in batch 601: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,481 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,492 - ERROR - Error in batch 602: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,493 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,503 - ERROR - Error in batch 603: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,503 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,514 - ERROR - Error in batch 604: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,514 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,524 - ERROR - Error in batch 605: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,524 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,534 - ERROR - Error in batch 606: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,534 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,545 - ERROR - Error in batch 607: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,545 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,556 - ERROR - Error in batch 608: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,556 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,567 - ERROR - Error in batch 609: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,567 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,578 - ERROR - Error in batch 610: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,578 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,588 - ERROR - Error in batch 611: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,589 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,600 - ERROR - Error in batch 612: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,601 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,610 - ERROR - Error in batch 613: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,611 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,621 - ERROR - Error in batch 614: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,621 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,630 - ERROR - Error in batch 615: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,631 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,640 - ERROR - Error in batch 616: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,641 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,652 - ERROR - Error in batch 617: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,652 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,663 - ERROR - Error in batch 618: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,663 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,674 - ERROR - Error in batch 619: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,674 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,683 - ERROR - Error in batch 620: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,684 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,693 - ERROR - Error in batch 621: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,694 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,703 - ERROR - Error in batch 622: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,704 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,714 - ERROR - Error in batch 623: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,714 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,723 - ERROR - Error in batch 624: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,724 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,735 - ERROR - Error in batch 625: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,735 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,744 - ERROR - Error in batch 626: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,745 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,756 - ERROR - Error in batch 627: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,756 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,767 - ERROR - Error in batch 628: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,767 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,776 - ERROR - Error in batch 629: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,777 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,787 - ERROR - Error in batch 630: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,787 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,796 - ERROR - Error in batch 631: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,797 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,806 - ERROR - Error in batch 632: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,807 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,816 - ERROR - Error in batch 633: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,817 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,827 - ERROR - Error in batch 634: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,828 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,837 - ERROR - Error in batch 635: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,838 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,847 - ERROR - Error in batch 636: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,848 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,857 - ERROR - Error in batch 637: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,858 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,867 - ERROR - Error in batch 638: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,868 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,877 - ERROR - Error in batch 639: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,878 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,887 - ERROR - Error in batch 640: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,888 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,897 - ERROR - Error in batch 641: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,898 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,907 - ERROR - Error in batch 642: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,908 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,917 - ERROR - Error in batch 643: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,918 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,929 - ERROR - Error in batch 644: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,929 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,938 - ERROR - Error in batch 645: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,939 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,948 - ERROR - Error in batch 646: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,949 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,959 - ERROR - Error in batch 647: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,959 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:36,969 - ERROR - Error in batch 648: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:36,969 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,044 - ERROR - Error in batch 649: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,045 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,055 - ERROR - Error in batch 650: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,056 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,065 - ERROR - Error in batch 651: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,066 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,077 - ERROR - Error in batch 652: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,077 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,086 - ERROR - Error in batch 653: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,087 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,096 - ERROR - Error in batch 654: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,097 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,106 - ERROR - Error in batch 655: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,107 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,117 - ERROR - Error in batch 656: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,117 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,126 - ERROR - Error in batch 657: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,127 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,136 - ERROR - Error in batch 658: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,137 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,146 - ERROR - Error in batch 659: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,147 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,156 - ERROR - Error in batch 660: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,157 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,168 - ERROR - Error in batch 661: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,168 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,177 - ERROR - Error in batch 662: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,178 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,187 - ERROR - Error in batch 663: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,188 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,198 - ERROR - Error in batch 664: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,198 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,208 - ERROR - Error in batch 665: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,208 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,217 - ERROR - Error in batch 666: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,218 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,228 - ERROR - Error in batch 667: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,229 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,238 - ERROR - Error in batch 668: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,239 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,250 - ERROR - Error in batch 669: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,250 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,260 - ERROR - Error in batch 670: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,260 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,269 - ERROR - Error in batch 671: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,270 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,279 - ERROR - Error in batch 672: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,280 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,289 - ERROR - Error in batch 673: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,290 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,299 - ERROR - Error in batch 674: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,300 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,309 - ERROR - Error in batch 675: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,310 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,320 - ERROR - Error in batch 676: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,320 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,330 - ERROR - Error in batch 677: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,331 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,340 - ERROR - Error in batch 678: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,341 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,350 - ERROR - Error in batch 679: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,351 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,362 - ERROR - Error in batch 680: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,362 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,373 - ERROR - Error in batch 681: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,373 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,383 - ERROR - Error in batch 682: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,384 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,393 - ERROR - Error in batch 683: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,394 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,404 - ERROR - Error in batch 684: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,405 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,416 - ERROR - Error in batch 685: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,416 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,426 - ERROR - Error in batch 686: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,426 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,435 - ERROR - Error in batch 687: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,436 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,446 - ERROR - Error in batch 688: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,446 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,455 - ERROR - Error in batch 689: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,456 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,465 - ERROR - Error in batch 690: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,466 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,477 - ERROR - Error in batch 691: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,477 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,487 - ERROR - Error in batch 692: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,487 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,496 - ERROR - Error in batch 693: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,497 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,506 - ERROR - Error in batch 694: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,507 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,516 - ERROR - Error in batch 695: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,517 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,526 - ERROR - Error in batch 696: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,527 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,536 - ERROR - Error in batch 697: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,537 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,546 - ERROR - Error in batch 698: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,547 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,556 - ERROR - Error in batch 699: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,557 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,567 - ERROR - Error in batch 700: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,568 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,580 - ERROR - Error in batch 701: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,580 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,589 - ERROR - Error in batch 702: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,590 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,600 - ERROR - Error in batch 703: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,600 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,609 - ERROR - Error in batch 704: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,610 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,619 - ERROR - Error in batch 705: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,620 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,629 - ERROR - Error in batch 706: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,630 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,641 - ERROR - Error in batch 707: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,641 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,650 - ERROR - Error in batch 708: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,651 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,662 - ERROR - Error in batch 709: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,662 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,672 - ERROR - Error in batch 710: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,672 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,682 - ERROR - Error in batch 711: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,682 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,691 - ERROR - Error in batch 712: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,692 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,701 - ERROR - Error in batch 713: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,702 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,711 - ERROR - Error in batch 714: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,712 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,721 - ERROR - Error in batch 715: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,722 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,732 - ERROR - Error in batch 716: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,732 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,741 - ERROR - Error in batch 717: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,742 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,751 - ERROR - Error in batch 718: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,752 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,762 - ERROR - Error in batch 719: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,762 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,771 - ERROR - Error in batch 720: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,772 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,782 - ERROR - Error in batch 721: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,782 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,791 - ERROR - Error in batch 722: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,792 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,801 - ERROR - Error in batch 723: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,802 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,812 - ERROR - Error in batch 724: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,812 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,822 - ERROR - Error in batch 725: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,822 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,831 - ERROR - Error in batch 726: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,832 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,841 - ERROR - Error in batch 727: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,842 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,851 - ERROR - Error in batch 728: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,852 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,862 - ERROR - Error in batch 729: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,862 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,872 - ERROR - Error in batch 730: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,873 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,883 - ERROR - Error in batch 731: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,883 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,892 - ERROR - Error in batch 732: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,893 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,903 - ERROR - Error in batch 733: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,903 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,912 - ERROR - Error in batch 734: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,913 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,922 - ERROR - Error in batch 735: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,923 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,932 - ERROR - Error in batch 736: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,933 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,942 - ERROR - Error in batch 737: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,943 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,952 - ERROR - Error in batch 738: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,953 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,964 - ERROR - Error in batch 739: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,964 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,973 - ERROR - Error in batch 740: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,974 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,984 - ERROR - Error in batch 741: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,984 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:37,993 - ERROR - Error in batch 742: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:37,994 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,003 - ERROR - Error in batch 743: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,004 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,014 - ERROR - Error in batch 744: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,014 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,023 - ERROR - Error in batch 745: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,024 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,033 - ERROR - Error in batch 746: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,034 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,043 - ERROR - Error in batch 747: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,044 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,054 - ERROR - Error in batch 748: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,054 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,064 - ERROR - Error in batch 749: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,064 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,139 - ERROR - Error in batch 750: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,140 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,149 - ERROR - Error in batch 751: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,150 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,159 - ERROR - Error in batch 752: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,160 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,170 - ERROR - Error in batch 753: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,170 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,179 - ERROR - Error in batch 754: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,180 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,189 - ERROR - Error in batch 755: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,190 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,199 - ERROR - Error in batch 756: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,200 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,209 - ERROR - Error in batch 757: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,210 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,219 - ERROR - Error in batch 758: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,220 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,229 - ERROR - Error in batch 759: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,230 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,240 - ERROR - Error in batch 760: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,240 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,251 - ERROR - Error in batch 761: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,252 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,262 - ERROR - Error in batch 762: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,262 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,273 - ERROR - Error in batch 763: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,274 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,284 - ERROR - Error in batch 764: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,284 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,295 - ERROR - Error in batch 765: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,295 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,306 - ERROR - Error in batch 766: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,306 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,317 - ERROR - Error in batch 767: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,317 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,328 - ERROR - Error in batch 768: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,328 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,339 - ERROR - Error in batch 769: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,339 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,351 - ERROR - Error in batch 770: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,351 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,362 - ERROR - Error in batch 771: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,362 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,373 - ERROR - Error in batch 772: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,373 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,384 - ERROR - Error in batch 773: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,384 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,394 - ERROR - Error in batch 774: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,394 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,405 - ERROR - Error in batch 775: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,405 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,416 - ERROR - Error in batch 776: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,416 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,427 - ERROR - Error in batch 777: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,427 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,439 - ERROR - Error in batch 778: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,440 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,450 - ERROR - Error in batch 779: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,450 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,461 - ERROR - Error in batch 780: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,461 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,472 - ERROR - Error in batch 781: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,473 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,483 - ERROR - Error in batch 782: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,483 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,494 - ERROR - Error in batch 783: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,494 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,505 - ERROR - Error in batch 784: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,505 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,516 - ERROR - Error in batch 785: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,516 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,527 - ERROR - Error in batch 786: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,527 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,538 - ERROR - Error in batch 787: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,539 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,549 - ERROR - Error in batch 788: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,549 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,560 - ERROR - Error in batch 789: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,561 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,571 - ERROR - Error in batch 790: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,571 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,582 - ERROR - Error in batch 791: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,583 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,593 - ERROR - Error in batch 792: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,593 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,604 - ERROR - Error in batch 793: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,604 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,615 - ERROR - Error in batch 794: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,616 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,626 - ERROR - Error in batch 795: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,626 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,637 - ERROR - Error in batch 796: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,637 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,648 - ERROR - Error in batch 797: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,648 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,659 - ERROR - Error in batch 798: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,659 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,670 - ERROR - Error in batch 799: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,670 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,681 - ERROR - Error in batch 800: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,681 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,692 - ERROR - Error in batch 801: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,693 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,703 - ERROR - Error in batch 802: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,703 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,713 - ERROR - Error in batch 803: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,713 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,724 - ERROR - Error in batch 804: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,724 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,735 - ERROR - Error in batch 805: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,735 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,746 - ERROR - Error in batch 806: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,747 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,757 - ERROR - Error in batch 807: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,757 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,768 - ERROR - Error in batch 808: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,769 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,779 - ERROR - Error in batch 809: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,779 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,790 - ERROR - Error in batch 810: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,790 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,801 - ERROR - Error in batch 811: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,802 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,812 - ERROR - Error in batch 812: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,812 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,823 - ERROR - Error in batch 813: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,823 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,834 - ERROR - Error in batch 814: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,834 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,845 - ERROR - Error in batch 815: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,846 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,856 - ERROR - Error in batch 816: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,856 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,867 - ERROR - Error in batch 817: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,867 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,878 - ERROR - Error in batch 818: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,878 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,889 - ERROR - Error in batch 819: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,890 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,900 - ERROR - Error in batch 820: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,900 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,911 - ERROR - Error in batch 821: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,911 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,922 - ERROR - Error in batch 822: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,922 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,934 - ERROR - Error in batch 823: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,935 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,945 - ERROR - Error in batch 824: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,945 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,956 - ERROR - Error in batch 825: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,956 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,967 - ERROR - Error in batch 826: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,968 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,978 - ERROR - Error in batch 827: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,978 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:38,989 - ERROR - Error in batch 828: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:38,989 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,000 - ERROR - Error in batch 829: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,000 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,011 - ERROR - Error in batch 830: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,012 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,022 - ERROR - Error in batch 831: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,022 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,034 - ERROR - Error in batch 832: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,034 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,045 - ERROR - Error in batch 833: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,045 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,056 - ERROR - Error in batch 834: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,056 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,067 - ERROR - Error in batch 835: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,067 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,079 - ERROR - Error in batch 836: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,080 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,090 - ERROR - Error in batch 837: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,090 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,101 - ERROR - Error in batch 838: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,102 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,112 - ERROR - Error in batch 839: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,112 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,123 - ERROR - Error in batch 840: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,124 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,134 - ERROR - Error in batch 841: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,134 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,145 - ERROR - Error in batch 842: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,145 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,156 - ERROR - Error in batch 843: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,157 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,170 - ERROR - Error in batch 844: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,171 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,241 - ERROR - Error in batch 845: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,241 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,252 - ERROR - Error in batch 846: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,252 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,263 - ERROR - Error in batch 847: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,263 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,275 - ERROR - Error in batch 848: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,275 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,286 - ERROR - Error in batch 849: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,286 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,297 - ERROR - Error in batch 850: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,298 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,309 - ERROR - Error in batch 851: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,309 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,320 - ERROR - Error in batch 852: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,320 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,332 - ERROR - Error in batch 853: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,333 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,343 - ERROR - Error in batch 854: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,343 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,354 - ERROR - Error in batch 855: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,355 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,365 - ERROR - Error in batch 856: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,365 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,376 - ERROR - Error in batch 857: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,377 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,387 - ERROR - Error in batch 858: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,387 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,398 - ERROR - Error in batch 859: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,398 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,409 - ERROR - Error in batch 860: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,409 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,420 - ERROR - Error in batch 861: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,420 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,431 - ERROR - Error in batch 862: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,431 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,442 - ERROR - Error in batch 863: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,443 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,453 - ERROR - Error in batch 864: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,453 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,464 - ERROR - Error in batch 865: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,464 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,475 - ERROR - Error in batch 866: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,475 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,486 - ERROR - Error in batch 867: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,487 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,497 - ERROR - Error in batch 868: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,497 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,508 - ERROR - Error in batch 869: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,508 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,519 - ERROR - Error in batch 870: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,519 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,530 - ERROR - Error in batch 871: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,531 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,541 - ERROR - Error in batch 872: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,541 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,552 - ERROR - Error in batch 873: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,552 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,563 - ERROR - Error in batch 874: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,563 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,574 - ERROR - Error in batch 875: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,574 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,585 - ERROR - Error in batch 876: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,585 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,596 - ERROR - Error in batch 877: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,596 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,607 - ERROR - Error in batch 878: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,607 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,618 - ERROR - Error in batch 879: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,618 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,629 - ERROR - Error in batch 880: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,629 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,640 - ERROR - Error in batch 881: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,640 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,651 - ERROR - Error in batch 882: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,651 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,662 - ERROR - Error in batch 883: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,662 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,673 - ERROR - Error in batch 884: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,673 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,684 - ERROR - Error in batch 885: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,684 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,695 - ERROR - Error in batch 886: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,695 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,706 - ERROR - Error in batch 887: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,706 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,717 - ERROR - Error in batch 888: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,717 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,728 - ERROR - Error in batch 889: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,728 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,739 - ERROR - Error in batch 890: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,739 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,750 - ERROR - Error in batch 891: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,750 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,761 - ERROR - Error in batch 892: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,761 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,772 - ERROR - Error in batch 893: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,772 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,783 - ERROR - Error in batch 894: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,783 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,794 - ERROR - Error in batch 895: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,794 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,805 - ERROR - Error in batch 896: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,805 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,816 - ERROR - Error in batch 897: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,817 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,828 - ERROR - Error in batch 898: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,828 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,839 - ERROR - Error in batch 899: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,839 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,850 - ERROR - Error in batch 900: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,850 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,861 - ERROR - Error in batch 901: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,861 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,872 - ERROR - Error in batch 902: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,873 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,882 - ERROR - Error in batch 903: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,883 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,893 - ERROR - Error in batch 904: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,893 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,902 - ERROR - Error in batch 905: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,903 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,913 - ERROR - Error in batch 906: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,913 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,922 - ERROR - Error in batch 907: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,923 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,933 - ERROR - Error in batch 908: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,934 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,945 - ERROR - Error in batch 909: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,945 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,954 - ERROR - Error in batch 910: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,955 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,965 - ERROR - Error in batch 911: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,965 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,974 - ERROR - Error in batch 912: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,975 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,984 - ERROR - Error in batch 913: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:39,985 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:39,995 - ERROR - Error in batch 914: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,000 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,011 - ERROR - Error in batch 915: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,011 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,021 - ERROR - Error in batch 916: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,022 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,031 - ERROR - Error in batch 917: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,032 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,041 - ERROR - Error in batch 918: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,042 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,052 - ERROR - Error in batch 919: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,053 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,063 - ERROR - Error in batch 920: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,063 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,073 - ERROR - Error in batch 921: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,073 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,082 - ERROR - Error in batch 922: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,083 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,092 - ERROR - Error in batch 923: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,093 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,102 - ERROR - Error in batch 924: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,103 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,112 - ERROR - Error in batch 925: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,113 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,122 - ERROR - Error in batch 926: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,123 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,132 - ERROR - Error in batch 927: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,133 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,142 - ERROR - Error in batch 928: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,143 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,152 - ERROR - Error in batch 929: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,153 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,163 - ERROR - Error in batch 930: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,163 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,173 - ERROR - Error in batch 931: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,173 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,182 - ERROR - Error in batch 932: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,183 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,193 - ERROR - Error in batch 933: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,193 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,202 - ERROR - Error in batch 934: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,203 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,212 - ERROR - Error in batch 935: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,213 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,222 - ERROR - Error in batch 936: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,223 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,232 - ERROR - Error in batch 937: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,233 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,243 - ERROR - Error in batch 938: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,244 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,255 - ERROR - Error in batch 939: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,256 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,270 - ERROR - Error in batch 940: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,270 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,340 - ERROR - Error in batch 941: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,341 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,351 - ERROR - Error in batch 942: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,351 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,360 - ERROR - Error in batch 943: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,361 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,370 - ERROR - Error in batch 944: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,371 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,380 - ERROR - Error in batch 945: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,381 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,392 - ERROR - Error in batch 946: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,392 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,402 - ERROR - Error in batch 947: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,402 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,411 - ERROR - Error in batch 948: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,412 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,421 - ERROR - Error in batch 949: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,422 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,432 - ERROR - Error in batch 950: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,433 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,442 - ERROR - Error in batch 951: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,443 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,452 - ERROR - Error in batch 952: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,453 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,463 - ERROR - Error in batch 953: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,463 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,472 - ERROR - Error in batch 954: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,473 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,483 - ERROR - Error in batch 955: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,483 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,494 - ERROR - Error in batch 956: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,494 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,503 - ERROR - Error in batch 957: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,504 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,513 - ERROR - Error in batch 958: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,514 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,523 - ERROR - Error in batch 959: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,524 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,533 - ERROR - Error in batch 960: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,534 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,543 - ERROR - Error in batch 961: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,544 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,555 - ERROR - Error in batch 962: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,555 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,566 - ERROR - Error in batch 963: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,566 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,576 - ERROR - Error in batch 964: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,577 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,586 - ERROR - Error in batch 965: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,587 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,598 - ERROR - Error in batch 966: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,598 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,608 - ERROR - Error in batch 967: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,609 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,619 - ERROR - Error in batch 968: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,620 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,630 - ERROR - Error in batch 969: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,630 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,640 - ERROR - Error in batch 970: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,641 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,650 - ERROR - Error in batch 971: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,651 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,660 - ERROR - Error in batch 972: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,661 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,671 - ERROR - Error in batch 973: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,671 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,681 - ERROR - Error in batch 974: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,681 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,691 - ERROR - Error in batch 975: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,691 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,700 - ERROR - Error in batch 976: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,701 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,710 - ERROR - Error in batch 977: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,711 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,721 - ERROR - Error in batch 978: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,721 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,730 - ERROR - Error in batch 979: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,731 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,741 - ERROR - Error in batch 980: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,741 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,750 - ERROR - Error in batch 981: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,751 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,760 - ERROR - Error in batch 982: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,761 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:56:40,771 - ERROR - Error in batch 983: CUDA out of memory. Tried to allocate 13.66 GiB. GPU 0 has a total capacity of 23.53 GiB of which 9.17 GiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 26.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:56:40,771 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 8 to avoid OOM (estimated: 54.6 GB)
2025-12-08 13:57:45,643 - INFO - Loaded config: {'vocab_size': '3,580,963', 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:57:45,713 - INFO - Using device: cuda
2025-12-08 13:57:45,729 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 13:57:45,729 - INFO - GPU Memory: 23.5 GB
2025-12-08 13:57:45,730 - INFO - CUDA memory management optimized with expandable_segments:True
2025-12-08 13:57:47,702 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 13:57:47,807 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 13:57:47,807 - INFO - Creating ELMo BiLM model...
2025-12-08 13:58:16,921 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 13:58:16,923 - INFO - Creating data loader...
2025-12-08 13:58:17,200 - INFO - Data loader created successfully
2025-12-08 13:58:17,200 - INFO - Starting training...
2025-12-08 13:58:17,200 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 512, 'hidden_dim': 1024, 'projection_dim': 256, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 16, 'num_layers': 1}
2025-12-08 13:58:17,200 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_135816
2025-12-08 13:58:17,522 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:17,788 - ERROR - Error in batch 0: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 13:58:17,789 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:17,855 - ERROR - Error in batch 1: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:17,860 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:17,948 - ERROR - Error in batch 2: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:17,952 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,032 - ERROR - Error in batch 3: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,037 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,119 - ERROR - Error in batch 4: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,123 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,205 - ERROR - Error in batch 5: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,209 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,291 - ERROR - Error in batch 6: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,295 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,444 - ERROR - Error in batch 7: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,449 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,528 - ERROR - Error in batch 8: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,533 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,614 - ERROR - Error in batch 9: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,618 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,699 - ERROR - Error in batch 10: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,703 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,783 - ERROR - Error in batch 11: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,788 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,869 - ERROR - Error in batch 12: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,874 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:18,955 - ERROR - Error in batch 13: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:18,959 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,042 - ERROR - Error in batch 14: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,047 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,126 - ERROR - Error in batch 15: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,131 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,214 - ERROR - Error in batch 16: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,218 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,299 - ERROR - Error in batch 17: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,304 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,385 - ERROR - Error in batch 18: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,389 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,471 - ERROR - Error in batch 19: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,475 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,605 - ERROR - Error in batch 20: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,609 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,691 - ERROR - Error in batch 21: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,695 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,777 - ERROR - Error in batch 22: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,782 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,862 - ERROR - Error in batch 23: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,867 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:19,950 - ERROR - Error in batch 24: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:19,954 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,036 - ERROR - Error in batch 25: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,041 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,121 - ERROR - Error in batch 26: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,126 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,207 - ERROR - Error in batch 27: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,211 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,291 - ERROR - Error in batch 28: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,296 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,376 - ERROR - Error in batch 29: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,381 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,461 - ERROR - Error in batch 30: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,466 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,548 - ERROR - Error in batch 31: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,553 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,671 - ERROR - Error in batch 32: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,676 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,757 - ERROR - Error in batch 33: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,762 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,844 - ERROR - Error in batch 34: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,848 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:20,929 - ERROR - Error in batch 35: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:20,934 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,015 - ERROR - Error in batch 36: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,020 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,101 - ERROR - Error in batch 37: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,106 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,188 - ERROR - Error in batch 38: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,193 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,274 - ERROR - Error in batch 39: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,278 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,359 - ERROR - Error in batch 40: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,364 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,446 - ERROR - Error in batch 41: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,450 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,531 - ERROR - Error in batch 42: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,535 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,616 - ERROR - Error in batch 43: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,621 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,779 - ERROR - Error in batch 44: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,783 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,841 - ERROR - Error in batch 45: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,845 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:21,926 - ERROR - Error in batch 46: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:21,931 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,013 - ERROR - Error in batch 47: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,017 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,100 - ERROR - Error in batch 48: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,104 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,185 - ERROR - Error in batch 49: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,190 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,271 - ERROR - Error in batch 50: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,276 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,357 - ERROR - Error in batch 51: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,362 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,444 - ERROR - Error in batch 52: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,449 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,531 - ERROR - Error in batch 53: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,535 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,618 - ERROR - Error in batch 54: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,622 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,703 - ERROR - Error in batch 55: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,708 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,789 - ERROR - Error in batch 56: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,794 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:22,924 - ERROR - Error in batch 57: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:22,929 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,009 - ERROR - Error in batch 58: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,014 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,097 - ERROR - Error in batch 59: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,102 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,183 - ERROR - Error in batch 60: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,189 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,269 - ERROR - Error in batch 61: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,274 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,356 - ERROR - Error in batch 62: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,360 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,444 - ERROR - Error in batch 63: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,448 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,530 - ERROR - Error in batch 64: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,534 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,615 - ERROR - Error in batch 65: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,619 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,701 - ERROR - Error in batch 66: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,706 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,789 - ERROR - Error in batch 67: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,793 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:23,873 - ERROR - Error in batch 68: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:23,879 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,001 - ERROR - Error in batch 69: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,006 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,087 - ERROR - Error in batch 70: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,092 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,173 - ERROR - Error in batch 71: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,178 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,260 - ERROR - Error in batch 72: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,265 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,345 - ERROR - Error in batch 73: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,350 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,431 - ERROR - Error in batch 74: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,435 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,515 - ERROR - Error in batch 75: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,520 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,602 - ERROR - Error in batch 76: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,606 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,687 - ERROR - Error in batch 77: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,692 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,775 - ERROR - Error in batch 78: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,779 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,860 - ERROR - Error in batch 79: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,865 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:24,945 - ERROR - Error in batch 80: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:24,950 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,105 - ERROR - Error in batch 81: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,109 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,172 - ERROR - Error in batch 82: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,177 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,257 - ERROR - Error in batch 83: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,262 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,345 - ERROR - Error in batch 84: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,349 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,429 - ERROR - Error in batch 85: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,434 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,516 - ERROR - Error in batch 86: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,520 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,601 - ERROR - Error in batch 87: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,605 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,687 - ERROR - Error in batch 88: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,692 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,774 - ERROR - Error in batch 89: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,778 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,859 - ERROR - Error in batch 90: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,864 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:25,945 - ERROR - Error in batch 91: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:25,950 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,031 - ERROR - Error in batch 92: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,035 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,118 - ERROR - Error in batch 93: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,122 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,248 - ERROR - Error in batch 94: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,253 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,335 - ERROR - Error in batch 95: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,339 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,421 - ERROR - Error in batch 96: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,426 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,507 - ERROR - Error in batch 97: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,511 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,592 - ERROR - Error in batch 98: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,597 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,679 - ERROR - Error in batch 99: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,683 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,763 - ERROR - Error in batch 100: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,768 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,849 - ERROR - Error in batch 101: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,854 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:26,935 - ERROR - Error in batch 102: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:26,939 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:27,021 - ERROR - Error in batch 103: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:27,026 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:27,106 - ERROR - Error in batch 104: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:27,111 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:27,191 - ERROR - Error in batch 105: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:27,196 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:27,316 - ERROR - Error in batch 106: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:27,321 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 13:58:27,402 - ERROR - Error in batch 107: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 23.53 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 21.11 GiB memory in use. Of the allocated memory 20.64 GiB is allocated by PyTorch, and 28.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-08 13:58:27,407 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 32 -> 2 (estimated: 109.3GB -> target: 8.0GB)
2025-12-08 14:01:15,894 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:01:16,055 - INFO - Using device: cuda
2025-12-08 14:01:16,072 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:01:16,072 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:01:16,072 - INFO - CUDA memory management optimized with expandable_segments:True
2025-12-08 14:01:18,044 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:01:18,148 - INFO - Updated vocab_size to: 3,580,963
2025-12-08 14:01:18,148 - INFO - Creating ELMo BiLM model...
2025-12-08 14:01:32,986 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:01:32,987 - INFO - Creating data loader...
2025-12-08 14:01:33,280 - INFO - Data loader created successfully
2025-12-08 14:01:33,280 - INFO - Starting training...
2025-12-08 14:01:33,281 - INFO - Config: {'vocab_size': 3580963, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:01:33,281 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_140132
2025-12-08 14:01:33,390 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,712 - ERROR - Error in batch 0: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,714 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,727 - ERROR - Error in batch 1: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,747 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,750 - ERROR - Error in batch 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,776 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,779 - ERROR - Error in batch 3: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,804 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,807 - ERROR - Error in batch 4: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,833 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,836 - ERROR - Error in batch 5: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,862 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,864 - ERROR - Error in batch 6: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,890 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,893 - ERROR - Error in batch 7: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,919 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,921 - ERROR - Error in batch 8: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,947 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,950 - ERROR - Error in batch 9: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:33,976 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:33,978 - ERROR - Error in batch 10: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,004 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,007 - ERROR - Error in batch 11: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,033 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,035 - ERROR - Error in batch 12: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,061 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,064 - ERROR - Error in batch 13: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,090 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,092 - ERROR - Error in batch 14: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,118 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,121 - ERROR - Error in batch 15: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,147 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,150 - ERROR - Error in batch 16: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,176 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,178 - ERROR - Error in batch 17: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,205 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,208 - ERROR - Error in batch 18: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,233 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,236 - ERROR - Error in batch 19: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,262 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,265 - ERROR - Error in batch 20: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,290 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,293 - ERROR - Error in batch 21: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,319 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,322 - ERROR - Error in batch 22: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,348 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,350 - ERROR - Error in batch 23: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,376 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,379 - ERROR - Error in batch 24: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,405 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,408 - ERROR - Error in batch 25: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,433 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,436 - ERROR - Error in batch 26: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,462 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,465 - ERROR - Error in batch 27: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,491 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,493 - ERROR - Error in batch 28: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,519 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,522 - ERROR - Error in batch 29: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,548 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,550 - ERROR - Error in batch 30: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,576 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,579 - ERROR - Error in batch 31: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,605 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,608 - ERROR - Error in batch 32: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,633 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,636 - ERROR - Error in batch 33: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,662 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,665 - ERROR - Error in batch 34: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,691 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,693 - ERROR - Error in batch 35: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,719 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,722 - ERROR - Error in batch 36: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,748 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,750 - ERROR - Error in batch 37: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,776 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,779 - ERROR - Error in batch 38: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,805 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,808 - ERROR - Error in batch 39: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,833 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,836 - ERROR - Error in batch 40: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,862 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,864 - ERROR - Error in batch 41: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,890 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,893 - ERROR - Error in batch 42: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,919 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,922 - ERROR - Error in batch 43: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,947 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,950 - ERROR - Error in batch 44: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:34,976 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:34,979 - ERROR - Error in batch 45: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,004 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,007 - ERROR - Error in batch 46: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,033 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,036 - ERROR - Error in batch 47: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,062 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,064 - ERROR - Error in batch 48: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,090 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,093 - ERROR - Error in batch 49: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,119 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,121 - ERROR - Error in batch 50: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,147 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,150 - ERROR - Error in batch 51: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,176 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,178 - ERROR - Error in batch 52: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,204 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,207 - ERROR - Error in batch 53: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,233 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,236 - ERROR - Error in batch 54: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,261 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,264 - ERROR - Error in batch 55: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,290 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,293 - ERROR - Error in batch 56: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,319 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,321 - ERROR - Error in batch 57: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,347 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,350 - ERROR - Error in batch 58: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,375 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,378 - ERROR - Error in batch 59: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,404 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,407 - ERROR - Error in batch 60: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,433 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,435 - ERROR - Error in batch 61: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,461 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,464 - ERROR - Error in batch 62: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,490 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,492 - ERROR - Error in batch 63: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,518 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,521 - ERROR - Error in batch 64: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,547 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,550 - ERROR - Error in batch 65: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,575 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,578 - ERROR - Error in batch 66: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,604 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,607 - ERROR - Error in batch 67: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,632 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,635 - ERROR - Error in batch 68: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,661 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,664 - ERROR - Error in batch 69: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,690 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,692 - ERROR - Error in batch 70: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,718 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,721 - ERROR - Error in batch 71: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,747 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,750 - ERROR - Error in batch 72: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,775 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,778 - ERROR - Error in batch 73: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,804 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,807 - ERROR - Error in batch 74: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,833 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,835 - ERROR - Error in batch 75: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,861 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,864 - ERROR - Error in batch 76: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,890 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,893 - ERROR - Error in batch 77: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,919 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,921 - ERROR - Error in batch 78: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,947 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,950 - ERROR - Error in batch 79: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:35,976 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:35,979 - ERROR - Error in batch 80: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:36,005 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:36,007 - ERROR - Error in batch 81: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:36,033 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:36,036 - ERROR - Error in batch 82: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:01:36,062 - WARNING - Large vocab_size (3,580,963) detected. Splitting batch 16 -> 4 (estimated: 27.3GB -> target: 8.0GB)
2025-12-08 14:01:36,064 - ERROR - Error in batch 83: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
2025-12-08 14:02:48,147 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:02:48,217 - INFO - Using device: cuda
2025-12-08 14:02:48,233 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:02:48,233 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:02:48,233 - INFO - CUDA memory management optimized with expandable_segments:True
2025-12-08 14:02:50,276 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:02:50,389 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:02:50,554 - INFO - Using vocab_size: 50,000
2025-12-08 14:02:50,554 - INFO - Creating ELMo BiLM model...
2025-12-08 14:02:51,517 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:02:51,519 - INFO - Creating data loader...
2025-12-08 14:02:51,521 - INFO - Data loader created successfully
2025-12-08 14:02:51,521 - INFO - Starting training...
2025-12-08 14:02:51,521 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:02:51,521 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_140251
2025-12-08 14:02:51,695 - ERROR - Error in batch 0: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-08 14:04:04,969 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:04:05,039 - INFO - Using device: cuda
2025-12-08 14:04:05,058 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:04:05,058 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:04:05,058 - INFO - CUDA debugging enabled with CUDA_LAUNCH_BLOCKING=1
2025-12-08 14:04:07,152 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:04:07,262 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:04:07,390 - INFO - Limited vocab contains 50,000 words
2025-12-08 14:04:07,390 - INFO - UNK token available: True
2025-12-08 14:04:07,390 - INFO - Using vocab_size: 50,000
2025-12-08 14:04:07,390 - INFO - Creating ELMo BiLM model...
2025-12-08 14:04:08,559 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:04:08,561 - INFO - Creating data loader...
2025-12-08 14:04:08,563 - INFO - Data loader created successfully
2025-12-08 14:04:08,564 - INFO - Starting training...
2025-12-08 14:04:08,564 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:04:08,564 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_140408
2025-12-08 14:05:28,455 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:05:28,522 - INFO - Using device: cuda
2025-12-08 14:05:28,540 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:05:28,540 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:05:28,540 - INFO - CUDA debugging enabled with CUDA_LAUNCH_BLOCKING=1
2025-12-08 14:05:30,517 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:05:30,620 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:05:30,747 - INFO - Limited vocab contains 50,000 words
2025-12-08 14:05:30,747 - INFO - UNK token available: True
2025-12-08 14:05:30,747 - INFO - Using vocab_size: 50,000
2025-12-08 14:05:30,747 - INFO - Creating ELMo BiLM model...
2025-12-08 14:05:31,637 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:05:31,639 - INFO - Creating data loader...
2025-12-08 14:05:31,641 - INFO - Data loader created successfully
2025-12-08 14:05:31,641 - INFO - Starting training...
2025-12-08 14:05:31,641 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:05:31,641 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_140531
2025-12-08 14:05:32,332 - ERROR - Error in batch 1: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,370 - ERROR - Error in batch 2: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,406 - ERROR - Error in batch 3: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,443 - ERROR - Error in batch 4: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,480 - ERROR - Error in batch 5: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,517 - ERROR - Error in batch 6: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,553 - ERROR - Error in batch 7: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,590 - ERROR - Error in batch 8: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,626 - ERROR - Error in batch 9: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,724 - ERROR - Error in batch 11: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,760 - ERROR - Error in batch 12: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,796 - ERROR - Error in batch 13: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,832 - ERROR - Error in batch 14: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,867 - ERROR - Error in batch 15: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,903 - ERROR - Error in batch 16: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,938 - ERROR - Error in batch 17: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:32,974 - ERROR - Error in batch 18: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,010 - ERROR - Error in batch 19: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,111 - ERROR - Error in batch 21: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,147 - ERROR - Error in batch 22: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,183 - ERROR - Error in batch 23: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,220 - ERROR - Error in batch 24: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,256 - ERROR - Error in batch 25: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,293 - ERROR - Error in batch 26: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,329 - ERROR - Error in batch 27: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,365 - ERROR - Error in batch 28: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,399 - ERROR - Error in batch 29: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,498 - ERROR - Error in batch 31: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,534 - ERROR - Error in batch 32: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,569 - ERROR - Error in batch 33: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,605 - ERROR - Error in batch 34: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,641 - ERROR - Error in batch 35: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,677 - ERROR - Error in batch 36: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,714 - ERROR - Error in batch 37: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,749 - ERROR - Error in batch 38: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,784 - ERROR - Error in batch 39: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,882 - ERROR - Error in batch 41: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,917 - ERROR - Error in batch 42: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,952 - ERROR - Error in batch 43: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:33,987 - ERROR - Error in batch 44: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,022 - ERROR - Error in batch 45: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,057 - ERROR - Error in batch 46: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,091 - ERROR - Error in batch 47: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,126 - ERROR - Error in batch 48: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,161 - ERROR - Error in batch 49: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,256 - ERROR - Error in batch 51: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,293 - ERROR - Error in batch 52: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,328 - ERROR - Error in batch 53: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,363 - ERROR - Error in batch 54: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,398 - ERROR - Error in batch 55: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,432 - ERROR - Error in batch 56: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,467 - ERROR - Error in batch 57: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,500 - ERROR - Error in batch 58: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,535 - ERROR - Error in batch 59: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,631 - ERROR - Error in batch 61: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,665 - ERROR - Error in batch 62: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,699 - ERROR - Error in batch 63: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,733 - ERROR - Error in batch 64: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,768 - ERROR - Error in batch 65: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,802 - ERROR - Error in batch 66: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,836 - ERROR - Error in batch 67: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,870 - ERROR - Error in batch 68: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:34,905 - ERROR - Error in batch 69: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,001 - ERROR - Error in batch 71: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,035 - ERROR - Error in batch 72: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,070 - ERROR - Error in batch 73: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,105 - ERROR - Error in batch 74: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,139 - ERROR - Error in batch 75: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,174 - ERROR - Error in batch 76: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,208 - ERROR - Error in batch 77: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,243 - ERROR - Error in batch 78: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,277 - ERROR - Error in batch 79: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,373 - ERROR - Error in batch 81: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,408 - ERROR - Error in batch 82: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,443 - ERROR - Error in batch 83: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,477 - ERROR - Error in batch 84: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,511 - ERROR - Error in batch 85: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,546 - ERROR - Error in batch 86: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,583 - ERROR - Error in batch 87: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,617 - ERROR - Error in batch 88: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,652 - ERROR - Error in batch 89: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,747 - ERROR - Error in batch 91: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,782 - ERROR - Error in batch 92: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,816 - ERROR - Error in batch 93: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,850 - ERROR - Error in batch 94: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,884 - ERROR - Error in batch 95: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,919 - ERROR - Error in batch 96: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,954 - ERROR - Error in batch 97: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:35,988 - ERROR - Error in batch 98: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,022 - ERROR - Error in batch 99: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,126 - ERROR - Error in batch 101: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,160 - ERROR - Error in batch 102: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,195 - ERROR - Error in batch 103: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,230 - ERROR - Error in batch 104: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,264 - ERROR - Error in batch 105: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,298 - ERROR - Error in batch 106: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,334 - ERROR - Error in batch 107: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,368 - ERROR - Error in batch 108: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,403 - ERROR - Error in batch 109: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,499 - ERROR - Error in batch 111: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,533 - ERROR - Error in batch 112: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,568 - ERROR - Error in batch 113: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,602 - ERROR - Error in batch 114: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,637 - ERROR - Error in batch 115: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,671 - ERROR - Error in batch 116: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,706 - ERROR - Error in batch 117: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,739 - ERROR - Error in batch 118: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,774 - ERROR - Error in batch 119: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,868 - ERROR - Error in batch 121: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,903 - ERROR - Error in batch 122: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,937 - ERROR - Error in batch 123: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:36,971 - ERROR - Error in batch 124: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,006 - ERROR - Error in batch 125: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,040 - ERROR - Error in batch 126: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,075 - ERROR - Error in batch 127: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,109 - ERROR - Error in batch 128: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,143 - ERROR - Error in batch 129: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,239 - ERROR - Error in batch 131: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,275 - ERROR - Error in batch 132: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,308 - ERROR - Error in batch 133: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,343 - ERROR - Error in batch 134: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,377 - ERROR - Error in batch 135: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,412 - ERROR - Error in batch 136: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,446 - ERROR - Error in batch 137: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,480 - ERROR - Error in batch 138: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,515 - ERROR - Error in batch 139: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,610 - ERROR - Error in batch 141: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,644 - ERROR - Error in batch 142: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,680 - ERROR - Error in batch 143: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,715 - ERROR - Error in batch 144: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,749 - ERROR - Error in batch 145: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,783 - ERROR - Error in batch 146: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,818 - ERROR - Error in batch 147: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,852 - ERROR - Error in batch 148: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,886 - ERROR - Error in batch 149: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:37,991 - ERROR - Error in batch 151: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,027 - ERROR - Error in batch 152: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,062 - ERROR - Error in batch 153: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,096 - ERROR - Error in batch 154: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,130 - ERROR - Error in batch 155: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,165 - ERROR - Error in batch 156: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:05:38,199 - ERROR - Error in batch 157: object of type 'ELMoIterableDataset' has no len()
2025-12-08 14:06:10,663 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:06:10,730 - INFO - Using device: cuda
2025-12-08 14:06:10,747 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:06:10,747 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:06:10,747 - INFO - CUDA debugging enabled with CUDA_LAUNCH_BLOCKING=1
2025-12-08 14:06:12,685 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:06:12,786 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:06:12,912 - INFO - Limited vocab contains 50,000 words
2025-12-08 14:06:12,912 - INFO - UNK token available: True
2025-12-08 14:06:12,912 - INFO - Using vocab_size: 50,000
2025-12-08 14:06:12,912 - INFO - Creating ELMo BiLM model...
2025-12-08 14:06:13,842 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:06:13,844 - INFO - Creating data loader...
2025-12-08 14:06:13,846 - INFO - Data loader created successfully
2025-12-08 14:06:13,846 - INFO - Starting training...
2025-12-08 14:06:13,846 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:06:13,846 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_140613
2025-12-08 14:14:22,274 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:14:22,341 - INFO - Using device: cuda
2025-12-08 14:14:22,358 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:14:22,358 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:14:22,358 - INFO - CUDA debugging enabled with CUDA_LAUNCH_BLOCKING=1
2025-12-08 14:14:24,351 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:14:24,454 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:14:24,582 - INFO - Limited vocab contains 50,000 words
2025-12-08 14:14:24,583 - INFO - UNK token available: True
2025-12-08 14:14:24,583 - INFO - Using vocab_size: 50,000
2025-12-08 14:14:24,583 - INFO - Creating ELMo BiLM model...
2025-12-08 14:14:25,488 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:14:25,489 - INFO - Creating data loader...
2025-12-08 14:14:25,492 - INFO - Data loader created successfully
2025-12-08 14:14:25,492 - INFO - Starting training...
2025-12-08 14:14:25,492 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:14:25,492 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_141425
2025-12-08 14:14:25,492 - INFO -  IterableDataset has no definite length. Using estimated batches: 97,656
2025-12-08 14:16:59,032 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:16:59,148 - INFO - Using device: cuda
2025-12-08 14:16:59,165 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 14:16:59,165 - INFO - GPU Memory: 23.5 GB
2025-12-08 14:16:59,165 - INFO - CUDA debugging enabled with CUDA_LAUNCH_BLOCKING=1
2025-12-08 14:17:01,135 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 14:17:01,238 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 14:17:01,366 - INFO - Limited vocab contains 50,000 words
2025-12-08 14:17:01,366 - INFO - UNK token available: True
2025-12-08 14:17:01,366 - INFO - Using vocab_size: 50,000
2025-12-08 14:17:01,366 - INFO - Creating ELMo BiLM model...
2025-12-08 14:17:02,284 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 14:17:02,286 - INFO - Creating data loader...
2025-12-08 14:17:02,289 - INFO - Data loader created successfully
2025-12-08 14:17:02,289 - INFO - Starting training...
2025-12-08 14:17:02,289 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 64, 'batch_size': 16, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 4, 'num_layers': 1}
2025-12-08 14:17:02,289 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_141702
2025-12-08 14:17:02,290 - INFO -  IterableDataset has no definite length. Using estimated batches: 97,656
2025-12-08 18:13:53,611 - INFO - Loaded config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 6, 'num_layers': 1}
2025-12-08 18:13:53,676 - INFO - Using device: cuda
2025-12-08 18:13:53,692 - INFO - GPU: NVIDIA GeForce RTX 4090
2025-12-08 18:13:53,693 - INFO - GPU Memory: 23.5 GB
2025-12-08 18:13:53,693 - INFO - GPU     ( )
2025-12-08 18:13:55,638 - INFO - Loaded vocabulary: 3,580,963 words
2025-12-08 18:13:55,740 - WARNING - Limiting vocab from 3,580,963 to 50,000 for memory efficiency
2025-12-08 18:13:55,867 - INFO - Limited vocab contains 50,000 words
2025-12-08 18:13:55,867 - INFO - UNK token available: True
2025-12-08 18:13:55,867 - INFO - Using vocab_size: 50,000
2025-12-08 18:13:55,867 - INFO - Creating ELMo BiLM model...
2025-12-08 18:13:56,770 - INFO - Checkpoints will be saved to: /home/ssai/Workspace/ELMo_repo/runs/checkpoints/depth-1/
2025-12-08 18:13:56,772 - INFO - Creating data loader...
2025-12-08 18:13:56,774 - INFO - Data loader created successfully
2025-12-08 18:13:56,774 - INFO - Starting training...
2025-12-08 18:13:56,774 - INFO - Config: {'vocab_size': 50000, 'embedding_dim': 256, 'hidden_dim': 512, 'projection_dim': 128, 'dropout': 0.1, 'seq_len': 128, 'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'seed': 42, 'num_workers': 6, 'num_layers': 1}
2025-12-08 18:13:56,774 - INFO - Metrics will be saved to: /home/ssai/Workspace/ELMo_repo/logs/run_20251208_181356
2025-12-08 18:13:56,774 - INFO -  IterableDataset has no definite length. Using estimated batches: 24,414
